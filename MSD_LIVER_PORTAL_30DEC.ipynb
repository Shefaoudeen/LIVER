{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.measure import marching_cubes\n",
    "from mpl_toolkits.mplot3d.art3d import Poly3DCollection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-31 12:11:13.088201: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-12-31 12:11:13.657013: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-12-31 12:11:13.657121: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-12-31 12:11:13.761152: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-31 12:11:13.956113: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-12-31 12:11:15.387799: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import nibabel as nib\n",
    "#%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv3D, MaxPooling3D, UpSampling3D, concatenate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from skimage.transform import resize\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import tensorflow as tf\n",
    "import scipy.ndimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-31 12:11:17.262493: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43460 MB memory:  -> device: 0, name: NVIDIA RTX A6000, pci bus id: 0000:51:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-31 12:11:51.001194: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "2024-12-31 12:11:51.337597: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2024-12-31 12:11:51.986431: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2024-12-31 12:11:59.449342: I external/local_xla/xla/service/service.cc:168] XLA service 0x718367a56670 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-12-31 12:11:59.449391: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA RTX A6000, Compute Capability 8.6\n",
      "2024-12-31 12:11:59.468365: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1735627319.637748    4031 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - ETA: 0s - loss: 45.9651 - accuracy: 0.7721 - dice_coefficient: 0.1430 - jaccard_index: 0.0793 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/icmr/myenv_py311/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 334s 22s/step - loss: 45.9651 - accuracy: 0.7721 - dice_coefficient: 0.1430 - jaccard_index: 0.0793 - val_loss: 0.1593 - val_accuracy: 0.8238 - val_dice_coefficient: 0.0503 - val_jaccard_index: 0.0262\n",
      "Epoch 2/200\n",
      "15/15 [==============================] - 317s 23s/step - loss: 0.1349 - accuracy: 0.8156 - dice_coefficient: 0.1168 - jaccard_index: 0.0641 - val_loss: 0.1072 - val_accuracy: 0.8047 - val_dice_coefficient: 0.2065 - val_jaccard_index: 0.1156\n",
      "Epoch 3/200\n",
      "15/15 [==============================] - 265s 19s/step - loss: 0.0928 - accuracy: 0.8191 - dice_coefficient: 0.2255 - jaccard_index: 0.1295 - val_loss: 0.0967 - val_accuracy: 0.8032 - val_dice_coefficient: 0.2711 - val_jaccard_index: 0.1574\n",
      "Epoch 4/200\n",
      "15/15 [==============================] - 244s 17s/step - loss: 0.0779 - accuracy: 0.8194 - dice_coefficient: 0.2594 - jaccard_index: 0.1509 - val_loss: 0.0873 - val_accuracy: 0.8101 - val_dice_coefficient: 0.4067 - val_jaccard_index: 0.2578\n",
      "Epoch 5/200\n",
      "15/15 [==============================] - 248s 18s/step - loss: 0.0783 - accuracy: 0.8167 - dice_coefficient: 0.2971 - jaccard_index: 0.1757 - val_loss: 0.0801 - val_accuracy: 0.8144 - val_dice_coefficient: 0.3453 - val_jaccard_index: 0.2093\n",
      "Epoch 6/200\n",
      "15/15 [==============================] - 254s 18s/step - loss: 0.1107 - accuracy: 0.8181 - dice_coefficient: 0.3329 - jaccard_index: 0.2016 - val_loss: 0.0939 - val_accuracy: 0.8229 - val_dice_coefficient: 0.2066 - val_jaccard_index: 0.1157\n",
      "Epoch 7/200\n",
      "15/15 [==============================] - 248s 18s/step - loss: 0.0776 - accuracy: 0.8204 - dice_coefficient: 0.2164 - jaccard_index: 0.1235 - val_loss: 0.0850 - val_accuracy: 0.8215 - val_dice_coefficient: 0.3523 - val_jaccard_index: 0.2155\n",
      "Epoch 8/200\n",
      "15/15 [==============================] - 253s 18s/step - loss: 0.0773 - accuracy: 0.8198 - dice_coefficient: 0.3453 - jaccard_index: 0.2134 - val_loss: 0.0891 - val_accuracy: 0.8131 - val_dice_coefficient: 0.2719 - val_jaccard_index: 0.1577\n",
      "Epoch 9/200\n",
      "15/15 [==============================] - 253s 18s/step - loss: 0.0678 - accuracy: 0.8199 - dice_coefficient: 0.3377 - jaccard_index: 0.2061 - val_loss: 0.0805 - val_accuracy: 0.8116 - val_dice_coefficient: 0.4216 - val_jaccard_index: 0.2696\n",
      "Epoch 10/200\n",
      "15/15 [==============================] - 253s 18s/step - loss: 0.0575 - accuracy: 0.8231 - dice_coefficient: 0.4615 - jaccard_index: 0.3016 - val_loss: 0.0745 - val_accuracy: 0.8137 - val_dice_coefficient: 0.4822 - val_jaccard_index: 0.3236\n",
      "Epoch 11/200\n",
      "15/15 [==============================] - 246s 18s/step - loss: 0.0597 - accuracy: 0.8213 - dice_coefficient: 0.4631 - jaccard_index: 0.3051 - val_loss: 0.0808 - val_accuracy: 0.8138 - val_dice_coefficient: 0.3361 - val_jaccard_index: 0.2022\n",
      "Epoch 12/200\n",
      "15/15 [==============================] - 250s 18s/step - loss: 0.0625 - accuracy: 0.8204 - dice_coefficient: 0.4204 - jaccard_index: 0.2693 - val_loss: 0.0789 - val_accuracy: 0.8219 - val_dice_coefficient: 0.3866 - val_jaccard_index: 0.2435\n",
      "Epoch 13/200\n",
      "15/15 [==============================] - 253s 18s/step - loss: 0.0566 - accuracy: 0.8230 - dice_coefficient: 0.4335 - jaccard_index: 0.2781 - val_loss: 0.0734 - val_accuracy: 0.8123 - val_dice_coefficient: 0.4930 - val_jaccard_index: 0.3300\n",
      "Epoch 14/200\n",
      "15/15 [==============================] - 241s 17s/step - loss: 0.0556 - accuracy: 0.8211 - dice_coefficient: 0.4422 - jaccard_index: 0.2866 - val_loss: 0.0695 - val_accuracy: 0.8236 - val_dice_coefficient: 0.4313 - val_jaccard_index: 0.2786\n",
      "Epoch 15/200\n",
      "15/15 [==============================] - 249s 18s/step - loss: 0.0501 - accuracy: 0.8236 - dice_coefficient: 0.4875 - jaccard_index: 0.3236 - val_loss: 0.0851 - val_accuracy: 0.8091 - val_dice_coefficient: 0.5051 - val_jaccard_index: 0.3449\n",
      "Epoch 16/200\n",
      "15/15 [==============================] - 252s 18s/step - loss: 0.0568 - accuracy: 0.8222 - dice_coefficient: 0.4663 - jaccard_index: 0.3085 - val_loss: 0.0731 - val_accuracy: 0.8205 - val_dice_coefficient: 0.4914 - val_jaccard_index: 0.3341\n",
      "Epoch 17/200\n",
      "15/15 [==============================] - 248s 18s/step - loss: 0.0522 - accuracy: 0.8229 - dice_coefficient: 0.5022 - jaccard_index: 0.3366 - val_loss: 0.0703 - val_accuracy: 0.8370 - val_dice_coefficient: 0.5040 - val_jaccard_index: 0.3413\n",
      "Epoch 18/200\n",
      "15/15 [==============================] - 248s 18s/step - loss: 0.0509 - accuracy: 0.8220 - dice_coefficient: 0.5018 - jaccard_index: 0.3372 - val_loss: 0.0695 - val_accuracy: 0.8156 - val_dice_coefficient: 0.4798 - val_jaccard_index: 0.3225\n",
      "Epoch 19/200\n",
      "15/15 [==============================] - 247s 18s/step - loss: 0.0495 - accuracy: 0.8228 - dice_coefficient: 0.5095 - jaccard_index: 0.3471 - val_loss: 0.0646 - val_accuracy: 0.8235 - val_dice_coefficient: 0.4501 - val_jaccard_index: 0.2954\n",
      "Epoch 20/200\n",
      "15/15 [==============================] - 248s 18s/step - loss: 0.0601 - accuracy: 0.8185 - dice_coefficient: 0.4656 - jaccard_index: 0.3073 - val_loss: 0.0549 - val_accuracy: 0.8375 - val_dice_coefficient: 0.4895 - val_jaccard_index: 0.3254\n",
      "Epoch 21/200\n",
      "15/15 [==============================] - 253s 18s/step - loss: 0.0529 - accuracy: 0.8208 - dice_coefficient: 0.4036 - jaccard_index: 0.2538 - val_loss: 0.0687 - val_accuracy: 0.8306 - val_dice_coefficient: 0.4230 - val_jaccard_index: 0.2709\n",
      "Epoch 22/200\n",
      "15/15 [==============================] - 247s 18s/step - loss: 0.0463 - accuracy: 0.8235 - dice_coefficient: 0.5012 - jaccard_index: 0.3361 - val_loss: 0.0575 - val_accuracy: 0.8444 - val_dice_coefficient: 0.5093 - val_jaccard_index: 0.3476\n",
      "Epoch 23/200\n",
      "15/15 [==============================] - 243s 17s/step - loss: 0.0434 - accuracy: 0.8233 - dice_coefficient: 0.5711 - jaccard_index: 0.4008 - val_loss: 0.0579 - val_accuracy: 0.8326 - val_dice_coefficient: 0.5426 - val_jaccard_index: 0.3794\n",
      "Epoch 24/200\n",
      "15/15 [==============================] - 250s 18s/step - loss: 0.0385 - accuracy: 0.8237 - dice_coefficient: 0.5942 - jaccard_index: 0.4239 - val_loss: 0.0640 - val_accuracy: 0.8334 - val_dice_coefficient: 0.5332 - val_jaccard_index: 0.3862\n",
      "Epoch 25/200\n",
      "15/15 [==============================] - 248s 18s/step - loss: 0.0381 - accuracy: 0.8235 - dice_coefficient: 0.5888 - jaccard_index: 0.4189 - val_loss: 0.0736 - val_accuracy: 0.8223 - val_dice_coefficient: 0.4495 - val_jaccard_index: 0.2957\n",
      "Epoch 26/200\n",
      "15/15 [==============================] - 248s 18s/step - loss: 0.0405 - accuracy: 0.8235 - dice_coefficient: 0.5559 - jaccard_index: 0.3870 - val_loss: 0.0842 - val_accuracy: 0.8151 - val_dice_coefficient: 0.4962 - val_jaccard_index: 0.3416\n",
      "Epoch 27/200\n",
      "15/15 [==============================] - 245s 18s/step - loss: 0.0437 - accuracy: 0.8224 - dice_coefficient: 0.5334 - jaccard_index: 0.3664 - val_loss: 0.0671 - val_accuracy: 0.8183 - val_dice_coefficient: 0.5724 - val_jaccard_index: 0.4019\n",
      "Epoch 28/200\n",
      "15/15 [==============================] - 248s 18s/step - loss: 0.0421 - accuracy: 0.8236 - dice_coefficient: 0.5707 - jaccard_index: 0.4030 - val_loss: 0.0691 - val_accuracy: 0.8146 - val_dice_coefficient: 0.5007 - val_jaccard_index: 0.3438\n",
      "Epoch 29/200\n",
      "15/15 [==============================] - 244s 17s/step - loss: 0.0380 - accuracy: 0.8234 - dice_coefficient: 0.6002 - jaccard_index: 0.4341 - val_loss: 0.0481 - val_accuracy: 0.8447 - val_dice_coefficient: 0.5441 - val_jaccard_index: 0.3798\n",
      "Epoch 30/200\n",
      "15/15 [==============================] - 251s 18s/step - loss: 0.0350 - accuracy: 0.8242 - dice_coefficient: 0.6200 - jaccard_index: 0.4510 - val_loss: 0.0567 - val_accuracy: 0.8232 - val_dice_coefficient: 0.5592 - val_jaccard_index: 0.3895\n",
      "Epoch 31/200\n",
      "15/15 [==============================] - 252s 18s/step - loss: 0.0333 - accuracy: 0.8240 - dice_coefficient: 0.6459 - jaccard_index: 0.4788 - val_loss: 0.0545 - val_accuracy: 0.8433 - val_dice_coefficient: 0.6176 - val_jaccard_index: 0.4570\n",
      "Epoch 32/200\n",
      "15/15 [==============================] - 249s 18s/step - loss: 0.0426 - accuracy: 0.8220 - dice_coefficient: 0.5470 - jaccard_index: 0.3859 - val_loss: 0.0544 - val_accuracy: 0.8428 - val_dice_coefficient: 0.4590 - val_jaccard_index: 0.3006\n",
      "Epoch 33/200\n",
      "15/15 [==============================] - 265s 19s/step - loss: 0.0413 - accuracy: 0.8235 - dice_coefficient: 0.5757 - jaccard_index: 0.4070 - val_loss: 0.0613 - val_accuracy: 0.8121 - val_dice_coefficient: 0.5424 - val_jaccard_index: 0.3805\n",
      "Epoch 34/200\n",
      "15/15 [==============================] - 260s 19s/step - loss: 0.0366 - accuracy: 0.8242 - dice_coefficient: 0.6251 - jaccard_index: 0.4572 - val_loss: 0.0616 - val_accuracy: 0.8217 - val_dice_coefficient: 0.6144 - val_jaccard_index: 0.4580\n",
      "Epoch 35/200\n",
      "15/15 [==============================] - 261s 19s/step - loss: 0.4303 - accuracy: 0.8049 - dice_coefficient: 0.2921 - jaccard_index: 0.2012 - val_loss: 1.6202 - val_accuracy: 0.7714 - val_dice_coefficient: 0.0656 - val_jaccard_index: 0.0341\n",
      "Epoch 36/200\n",
      "15/15 [==============================] - 258s 18s/step - loss: 0.2737 - accuracy: 0.8167 - dice_coefficient: 0.1035 - jaccard_index: 0.0549 - val_loss: 0.1108 - val_accuracy: 0.8043 - val_dice_coefficient: 0.1615 - val_jaccard_index: 0.0881\n",
      "Epoch 37/200\n",
      "15/15 [==============================] - 260s 19s/step - loss: 0.0900 - accuracy: 0.8176 - dice_coefficient: 0.1788 - jaccard_index: 0.0987 - val_loss: 0.0908 - val_accuracy: 0.8230 - val_dice_coefficient: 0.2107 - val_jaccard_index: 0.1179\n",
      "Epoch 38/200\n",
      "15/15 [==============================] - 259s 18s/step - loss: 0.0841 - accuracy: 0.8194 - dice_coefficient: 0.2072 - jaccard_index: 0.1173 - val_loss: 0.0884 - val_accuracy: 0.8108 - val_dice_coefficient: 0.2866 - val_jaccard_index: 0.1681\n",
      "Epoch 39/200\n",
      "15/15 [==============================] - 257s 18s/step - loss: 0.0744 - accuracy: 0.8195 - dice_coefficient: 0.2603 - jaccard_index: 0.1509 - val_loss: 0.0732 - val_accuracy: 0.8375 - val_dice_coefficient: 0.2622 - val_jaccard_index: 0.1515\n",
      "Epoch 40/200\n",
      "15/15 [==============================] - 260s 19s/step - loss: 0.0643 - accuracy: 0.8194 - dice_coefficient: 0.3134 - jaccard_index: 0.1868 - val_loss: 0.0773 - val_accuracy: 0.8237 - val_dice_coefficient: 0.3472 - val_jaccard_index: 0.2105\n",
      "Epoch 41/200\n",
      "15/15 [==============================] - 260s 19s/step - loss: 0.0557 - accuracy: 0.8214 - dice_coefficient: 0.4129 - jaccard_index: 0.2618 - val_loss: 0.0668 - val_accuracy: 0.8320 - val_dice_coefficient: 0.4435 - val_jaccard_index: 0.2886\n",
      "Epoch 42/200\n",
      "15/15 [==============================] - 249s 18s/step - loss: 0.0448 - accuracy: 0.8237 - dice_coefficient: 0.5637 - jaccard_index: 0.3942 - val_loss: 0.0501 - val_accuracy: 0.8454 - val_dice_coefficient: 0.5584 - val_jaccard_index: 0.3930\n",
      "Epoch 43/200\n",
      "15/15 [==============================] - 252s 18s/step - loss: 0.0368 - accuracy: 0.8249 - dice_coefficient: 0.6457 - jaccard_index: 0.4806 - val_loss: 0.0615 - val_accuracy: 0.8248 - val_dice_coefficient: 0.6338 - val_jaccard_index: 0.4680\n",
      "Epoch 44/200\n",
      "15/15 [==============================] - 246s 18s/step - loss: 0.0294 - accuracy: 0.8258 - dice_coefficient: 0.7209 - jaccard_index: 0.5673 - val_loss: 0.0487 - val_accuracy: 0.8455 - val_dice_coefficient: 0.5791 - val_jaccard_index: 0.4243\n",
      "Epoch 45/200\n",
      "15/15 [==============================] - 249s 18s/step - loss: 0.0307 - accuracy: 0.8258 - dice_coefficient: 0.6643 - jaccard_index: 0.5027 - val_loss: 0.0592 - val_accuracy: 0.8385 - val_dice_coefficient: 0.7229 - val_jaccard_index: 0.5670\n",
      "Epoch 46/200\n",
      "15/15 [==============================] - 245s 17s/step - loss: 0.0279 - accuracy: 0.8258 - dice_coefficient: 0.7205 - jaccard_index: 0.5672 - val_loss: 0.0763 - val_accuracy: 0.8328 - val_dice_coefficient: 0.5915 - val_jaccard_index: 0.4386\n",
      "Epoch 47/200\n",
      "15/15 [==============================] - 252s 18s/step - loss: 0.0331 - accuracy: 0.8253 - dice_coefficient: 0.6918 - jaccard_index: 0.5358 - val_loss: 0.0553 - val_accuracy: 0.8241 - val_dice_coefficient: 0.5773 - val_jaccard_index: 0.4266\n",
      "Epoch 48/200\n",
      "15/15 [==============================] - 252s 18s/step - loss: 0.0295 - accuracy: 0.8264 - dice_coefficient: 0.6819 - jaccard_index: 0.5242 - val_loss: 0.0656 - val_accuracy: 0.8172 - val_dice_coefficient: 0.6772 - val_jaccard_index: 0.5173\n",
      "Epoch 49/200\n",
      "15/15 [==============================] - 248s 18s/step - loss: 0.0261 - accuracy: 0.8261 - dice_coefficient: 0.7277 - jaccard_index: 0.5747 - val_loss: 0.0921 - val_accuracy: 0.8348 - val_dice_coefficient: 0.6177 - val_jaccard_index: 0.4682\n",
      "Epoch 50/200\n",
      "15/15 [==============================] - 253s 18s/step - loss: 145.8345 - accuracy: 0.6784 - dice_coefficient: 0.5364 - jaccard_index: 0.4177 - val_loss: 0.2794 - val_accuracy: 0.8232 - val_dice_coefficient: 0.0321 - val_jaccard_index: 0.0165\n",
      "Epoch 51/200\n",
      "15/15 [==============================] - 252s 18s/step - loss: 2.5484 - accuracy: 0.8193 - dice_coefficient: 0.0321 - jaccard_index: 0.0182 - val_loss: 0.4784 - val_accuracy: 0.8047 - val_dice_coefficient: 0.0804 - val_jaccard_index: 0.0421\n",
      "Epoch 52/200\n",
      "15/15 [==============================] - 249s 18s/step - loss: 0.6185 - accuracy: 0.8191 - dice_coefficient: 0.0303 - jaccard_index: 0.0156 - val_loss: 4.0850 - val_accuracy: 0.8043 - val_dice_coefficient: 1.7414e-05 - val_jaccard_index: 1.4976e-05\n",
      "Epoch 53/200\n",
      "15/15 [==============================] - 247s 18s/step - loss: 0.5432 - accuracy: 0.7921 - dice_coefficient: 0.0504 - jaccard_index: 0.0286 - val_loss: 0.3322 - val_accuracy: 0.7688 - val_dice_coefficient: 0.0733 - val_jaccard_index: 0.0382\n",
      "Epoch 54/200\n",
      "15/15 [==============================] - 253s 18s/step - loss: 0.2879 - accuracy: 0.8153 - dice_coefficient: 0.0164 - jaccard_index: 0.0085 - val_loss: 0.3459 - val_accuracy: 0.8374 - val_dice_coefficient: 0.0075 - val_jaccard_index: 0.0038\n",
      "Epoch 55/200\n",
      "15/15 [==============================] - 244s 17s/step - loss: 0.1852 - accuracy: 0.8167 - dice_coefficient: 0.0523 - jaccard_index: 0.0279 - val_loss: 0.1392 - val_accuracy: 0.8227 - val_dice_coefficient: 0.0942 - val_jaccard_index: 0.0500\n",
      "Epoch 56/200\n",
      "15/15 [==============================] - 244s 17s/step - loss: 0.0992 - accuracy: 0.8164 - dice_coefficient: 0.1610 - jaccard_index: 0.0896 - val_loss: 0.1232 - val_accuracy: 0.8128 - val_dice_coefficient: 0.1282 - val_jaccard_index: 0.0694\n",
      "Epoch 57/200\n",
      "15/15 [==============================] - 255s 18s/step - loss: 0.0814 - accuracy: 0.8182 - dice_coefficient: 0.1942 - jaccard_index: 0.1102 - val_loss: 0.1223 - val_accuracy: 0.8220 - val_dice_coefficient: 0.2370 - val_jaccard_index: 0.1349\n",
      "Epoch 58/200\n",
      "15/15 [==============================] - 239s 17s/step - loss: 0.0721 - accuracy: 0.8189 - dice_coefficient: 0.2688 - jaccard_index: 0.1565 - val_loss: 0.0928 - val_accuracy: 0.8046 - val_dice_coefficient: 0.2972 - val_jaccard_index: 0.1759\n",
      "Epoch 59/200\n",
      "15/15 [==============================] - 226s 16s/step - loss: 0.0699 - accuracy: 0.8192 - dice_coefficient: 0.2836 - jaccard_index: 0.1670 - val_loss: 0.0712 - val_accuracy: 0.8271 - val_dice_coefficient: 0.3302 - val_jaccard_index: 0.1984\n",
      "Epoch 60/200\n",
      "15/15 [==============================] - 229s 16s/step - loss: 0.0696 - accuracy: 0.8190 - dice_coefficient: 0.2945 - jaccard_index: 0.1737 - val_loss: 0.0859 - val_accuracy: 0.8049 - val_dice_coefficient: 0.3085 - val_jaccard_index: 0.1831\n",
      "Epoch 61/200\n",
      "15/15 [==============================] - 227s 16s/step - loss: 0.0614 - accuracy: 0.8205 - dice_coefficient: 0.3195 - jaccard_index: 0.1917 - val_loss: 0.1349 - val_accuracy: 0.8173 - val_dice_coefficient: 0.3294 - val_jaccard_index: 0.1992\n",
      "Epoch 62/200\n",
      "15/15 [==============================] - 226s 16s/step - loss: 0.0636 - accuracy: 0.8198 - dice_coefficient: 0.3430 - jaccard_index: 0.2089 - val_loss: 0.0813 - val_accuracy: 0.8136 - val_dice_coefficient: 0.3018 - val_jaccard_index: 0.1784\n",
      "Epoch 63/200\n",
      "15/15 [==============================] - 238s 17s/step - loss: 0.0769 - accuracy: 0.8193 - dice_coefficient: 0.2463 - jaccard_index: 0.1413 - val_loss: 0.0982 - val_accuracy: 0.8125 - val_dice_coefficient: 0.2629 - val_jaccard_index: 0.1523\n",
      "Epoch 64/200\n",
      "15/15 [==============================] - 243s 17s/step - loss: 0.0722 - accuracy: 0.8198 - dice_coefficient: 0.2772 - jaccard_index: 0.1620 - val_loss: 0.0769 - val_accuracy: 0.8205 - val_dice_coefficient: 0.3541 - val_jaccard_index: 0.2175\n",
      "Epoch 65/200\n",
      "15/15 [==============================] - 244s 17s/step - loss: 0.0662 - accuracy: 0.8208 - dice_coefficient: 0.3378 - jaccard_index: 0.2049 - val_loss: 0.0869 - val_accuracy: 0.8128 - val_dice_coefficient: 0.2695 - val_jaccard_index: 0.1569\n",
      "Epoch 66/200\n",
      "15/15 [==============================] - 241s 17s/step - loss: 0.0631 - accuracy: 0.8210 - dice_coefficient: 0.3457 - jaccard_index: 0.2101 - val_loss: 0.0721 - val_accuracy: 0.8263 - val_dice_coefficient: 0.3336 - val_jaccard_index: 0.2007\n",
      "Epoch 67/200\n",
      "15/15 [==============================] - 248s 18s/step - loss: 0.0572 - accuracy: 0.8217 - dice_coefficient: 0.3728 - jaccard_index: 0.2307 - val_loss: 0.0777 - val_accuracy: 0.8215 - val_dice_coefficient: 0.4012 - val_jaccard_index: 0.2526\n",
      "Epoch 68/200\n",
      "15/15 [==============================] - 241s 17s/step - loss: 0.0538 - accuracy: 0.8215 - dice_coefficient: 0.3926 - jaccard_index: 0.2453 - val_loss: 0.1007 - val_accuracy: 0.8295 - val_dice_coefficient: 0.4198 - val_jaccard_index: 0.2745\n",
      "Epoch 69/200\n",
      "15/15 [==============================] - 241s 17s/step - loss: 0.0519 - accuracy: 0.8214 - dice_coefficient: 0.4079 - jaccard_index: 0.2580 - val_loss: 0.0705 - val_accuracy: 0.8200 - val_dice_coefficient: 0.4004 - val_jaccard_index: 0.2515\n",
      "Epoch 70/200\n",
      "15/15 [==============================] - 248s 18s/step - loss: 0.0512 - accuracy: 0.8223 - dice_coefficient: 0.4122 - jaccard_index: 0.2617 - val_loss: 0.0914 - val_accuracy: 0.8186 - val_dice_coefficient: 0.4518 - val_jaccard_index: 0.2933\n",
      "Epoch 71/200\n",
      "15/15 [==============================] - 247s 18s/step - loss: 0.0512 - accuracy: 0.8223 - dice_coefficient: 0.4285 - jaccard_index: 0.2741 - val_loss: 0.0732 - val_accuracy: 0.8112 - val_dice_coefficient: 0.3984 - val_jaccard_index: 0.2497\n",
      "Epoch 72/200\n",
      "15/15 [==============================] - 247s 18s/step - loss: 0.0558 - accuracy: 0.8225 - dice_coefficient: 0.3974 - jaccard_index: 0.2493 - val_loss: 0.0708 - val_accuracy: 0.8223 - val_dice_coefficient: 0.4326 - val_jaccard_index: 0.2782\n",
      "Epoch 73/200\n",
      "15/15 [==============================] - 243s 17s/step - loss: 0.0514 - accuracy: 0.8229 - dice_coefficient: 0.4311 - jaccard_index: 0.2766 - val_loss: 0.0716 - val_accuracy: 0.8113 - val_dice_coefficient: 0.4035 - val_jaccard_index: 0.2531\n",
      "Epoch 74/200\n",
      "15/15 [==============================] - 246s 18s/step - loss: 0.0493 - accuracy: 0.8230 - dice_coefficient: 0.4651 - jaccard_index: 0.3040 - val_loss: 0.0538 - val_accuracy: 0.8362 - val_dice_coefficient: 0.4588 - val_jaccard_index: 0.2994\n",
      "Epoch 75/200\n",
      "15/15 [==============================] - 239s 17s/step - loss: 0.0456 - accuracy: 0.8233 - dice_coefficient: 0.4723 - jaccard_index: 0.3102 - val_loss: 0.0666 - val_accuracy: 0.8318 - val_dice_coefficient: 0.4828 - val_jaccard_index: 0.3245\n",
      "Epoch 76/200\n",
      "15/15 [==============================] - 241s 17s/step - loss: 0.0459 - accuracy: 0.8232 - dice_coefficient: 0.4800 - jaccard_index: 0.3177 - val_loss: 0.0763 - val_accuracy: 0.8323 - val_dice_coefficient: 0.4556 - val_jaccard_index: 0.3024\n",
      "Epoch 77/200\n",
      "15/15 [==============================] - 241s 17s/step - loss: 0.0443 - accuracy: 0.8232 - dice_coefficient: 0.5009 - jaccard_index: 0.3363 - val_loss: 0.0756 - val_accuracy: 0.8109 - val_dice_coefficient: 0.4258 - val_jaccard_index: 0.2710\n",
      "Epoch 78/200\n",
      "15/15 [==============================] - 240s 17s/step - loss: 0.0472 - accuracy: 0.8223 - dice_coefficient: 0.4782 - jaccard_index: 0.3164 - val_loss: 0.0723 - val_accuracy: 0.8139 - val_dice_coefficient: 0.4498 - val_jaccard_index: 0.2931\n",
      "Epoch 79/200\n",
      "15/15 [==============================] - 247s 18s/step - loss: 0.0453 - accuracy: 0.8234 - dice_coefficient: 0.4853 - jaccard_index: 0.3217 - val_loss: 0.0515 - val_accuracy: 0.8352 - val_dice_coefficient: 0.5557 - val_jaccard_index: 0.3878\n",
      "Epoch 80/200\n",
      "15/15 [==============================] - 246s 18s/step - loss: 0.0439 - accuracy: 0.8234 - dice_coefficient: 0.5022 - jaccard_index: 0.3367 - val_loss: 0.0629 - val_accuracy: 0.8435 - val_dice_coefficient: 0.4657 - val_jaccard_index: 0.3078\n",
      "Epoch 81/200\n",
      "15/15 [==============================] - 240s 17s/step - loss: 0.0438 - accuracy: 0.8236 - dice_coefficient: 0.5055 - jaccard_index: 0.3406 - val_loss: 0.0495 - val_accuracy: 0.8379 - val_dice_coefficient: 0.5170 - val_jaccard_index: 0.3515\n",
      "Epoch 82/200\n",
      "15/15 [==============================] - 239s 17s/step - loss: 0.0430 - accuracy: 0.8239 - dice_coefficient: 0.5161 - jaccard_index: 0.3489 - val_loss: 0.0562 - val_accuracy: 0.8322 - val_dice_coefficient: 0.4833 - val_jaccard_index: 0.3214\n",
      "Epoch 83/200\n",
      "15/15 [==============================] - 244s 17s/step - loss: 0.0432 - accuracy: 0.8237 - dice_coefficient: 0.5226 - jaccard_index: 0.3551 - val_loss: 0.0637 - val_accuracy: 0.8139 - val_dice_coefficient: 0.5369 - val_jaccard_index: 0.3703\n",
      "Epoch 84/200\n",
      "15/15 [==============================] - 247s 18s/step - loss: 0.0414 - accuracy: 0.8240 - dice_coefficient: 0.5320 - jaccard_index: 0.3652 - val_loss: 0.0629 - val_accuracy: 0.8203 - val_dice_coefficient: 0.5612 - val_jaccard_index: 0.3927\n",
      "Epoch 85/200\n",
      "15/15 [==============================] - 248s 18s/step - loss: 0.0416 - accuracy: 0.8241 - dice_coefficient: 0.5375 - jaccard_index: 0.3698 - val_loss: 0.0631 - val_accuracy: 0.8154 - val_dice_coefficient: 0.5456 - val_jaccard_index: 0.3812\n",
      "Epoch 86/200\n",
      "15/15 [==============================] - 242s 17s/step - loss: 0.0403 - accuracy: 0.8239 - dice_coefficient: 0.5497 - jaccard_index: 0.3807 - val_loss: 0.0618 - val_accuracy: 0.8332 - val_dice_coefficient: 0.5103 - val_jaccard_index: 0.3525\n",
      "Epoch 87/200\n",
      "15/15 [==============================] - 243s 17s/step - loss: 0.0388 - accuracy: 0.8242 - dice_coefficient: 0.5671 - jaccard_index: 0.3973 - val_loss: 0.0648 - val_accuracy: 0.8230 - val_dice_coefficient: 0.5524 - val_jaccard_index: 0.3954\n",
      "Epoch 88/200\n",
      "15/15 [==============================] - 238s 17s/step - loss: 0.0373 - accuracy: 0.8245 - dice_coefficient: 0.5705 - jaccard_index: 0.4012 - val_loss: 0.0792 - val_accuracy: 0.8144 - val_dice_coefficient: 0.5469 - val_jaccard_index: 0.3811\n",
      "Epoch 89/200\n",
      "15/15 [==============================] - 244s 17s/step - loss: 0.0372 - accuracy: 0.8242 - dice_coefficient: 0.5884 - jaccard_index: 0.4206 - val_loss: 0.0711 - val_accuracy: 0.8202 - val_dice_coefficient: 0.5882 - val_jaccard_index: 0.4180\n",
      "Epoch 90/200\n",
      "15/15 [==============================] - 246s 18s/step - loss: 0.0409 - accuracy: 0.8239 - dice_coefficient: 0.5394 - jaccard_index: 0.3720 - val_loss: 0.0734 - val_accuracy: 0.8234 - val_dice_coefficient: 0.5501 - val_jaccard_index: 0.3887\n",
      "Epoch 91/200\n",
      "15/15 [==============================] - 243s 17s/step - loss: 0.0366 - accuracy: 0.8246 - dice_coefficient: 0.5751 - jaccard_index: 0.4052 - val_loss: 0.0672 - val_accuracy: 0.8160 - val_dice_coefficient: 0.5838 - val_jaccard_index: 0.4157\n",
      "Epoch 92/200\n",
      "15/15 [==============================] - 244s 17s/step - loss: 0.0349 - accuracy: 0.8249 - dice_coefficient: 0.6022 - jaccard_index: 0.4328 - val_loss: 0.0935 - val_accuracy: 0.8332 - val_dice_coefficient: 0.5633 - val_jaccard_index: 0.4070\n",
      "Epoch 93/200\n",
      "15/15 [==============================] - 246s 18s/step - loss: 0.0349 - accuracy: 0.8246 - dice_coefficient: 0.6125 - jaccard_index: 0.4441 - val_loss: 0.0850 - val_accuracy: 0.8139 - val_dice_coefficient: 0.5999 - val_jaccard_index: 0.4420\n",
      "Epoch 94/200\n",
      "15/15 [==============================] - 245s 17s/step - loss: 0.0363 - accuracy: 0.8243 - dice_coefficient: 0.6186 - jaccard_index: 0.4497 - val_loss: 0.0890 - val_accuracy: 0.8308 - val_dice_coefficient: 0.5642 - val_jaccard_index: 0.4089\n",
      "Epoch 95/200\n",
      "15/15 [==============================] - 244s 17s/step - loss: 0.0391 - accuracy: 0.8238 - dice_coefficient: 0.5846 - jaccard_index: 0.4148 - val_loss: 0.1091 - val_accuracy: 0.8209 - val_dice_coefficient: 0.4589 - val_jaccard_index: 0.2996\n",
      "Epoch 96/200\n",
      "15/15 [==============================] - 243s 17s/step - loss: 0.0351 - accuracy: 0.8246 - dice_coefficient: 0.6051 - jaccard_index: 0.4362 - val_loss: 0.0671 - val_accuracy: 0.8245 - val_dice_coefficient: 0.5836 - val_jaccard_index: 0.4166\n",
      "Epoch 97/200\n",
      "15/15 [==============================] - 246s 18s/step - loss: 0.0320 - accuracy: 0.8254 - dice_coefficient: 0.6410 - jaccard_index: 0.4731 - val_loss: 0.0942 - val_accuracy: 0.8335 - val_dice_coefficient: 0.5980 - val_jaccard_index: 0.4361\n",
      "Epoch 98/200\n",
      "15/15 [==============================] - 243s 17s/step - loss: 0.0319 - accuracy: 0.8251 - dice_coefficient: 0.6425 - jaccard_index: 0.4753 - val_loss: 0.1185 - val_accuracy: 0.8149 - val_dice_coefficient: 0.6143 - val_jaccard_index: 0.4503\n",
      "Epoch 99/200\n",
      "15/15 [==============================] - 238s 17s/step - loss: 0.0314 - accuracy: 0.8252 - dice_coefficient: 0.6622 - jaccard_index: 0.4969 - val_loss: 0.0860 - val_accuracy: 0.8158 - val_dice_coefficient: 0.6353 - val_jaccard_index: 0.4709\n",
      "Epoch 100/200\n",
      "15/15 [==============================] - 241s 17s/step - loss: 0.0311 - accuracy: 0.8255 - dice_coefficient: 0.6585 - jaccard_index: 0.4928 - val_loss: 0.0635 - val_accuracy: 0.8392 - val_dice_coefficient: 0.6694 - val_jaccard_index: 0.5046\n",
      "Epoch 101/200\n",
      "15/15 [==============================] - 243s 17s/step - loss: 0.0314 - accuracy: 0.8251 - dice_coefficient: 0.6655 - jaccard_index: 0.5009 - val_loss: 0.0842 - val_accuracy: 0.8249 - val_dice_coefficient: 0.6244 - val_jaccard_index: 0.4562\n",
      "Epoch 102/200\n",
      "15/15 [==============================] - 247s 18s/step - loss: 0.0315 - accuracy: 0.8255 - dice_coefficient: 0.6559 - jaccard_index: 0.4902 - val_loss: 0.0614 - val_accuracy: 0.8341 - val_dice_coefficient: 0.6171 - val_jaccard_index: 0.4481\n",
      "Epoch 103/200\n",
      "15/15 [==============================] - 243s 17s/step - loss: 0.0323 - accuracy: 0.8254 - dice_coefficient: 0.6513 - jaccard_index: 0.4845 - val_loss: 0.0513 - val_accuracy: 0.8246 - val_dice_coefficient: 0.6254 - val_jaccard_index: 0.4677\n",
      "Epoch 104/200\n",
      "15/15 [==============================] - 239s 17s/step - loss: 0.0303 - accuracy: 0.8253 - dice_coefficient: 0.6610 - jaccard_index: 0.4958 - val_loss: 0.0418 - val_accuracy: 0.8448 - val_dice_coefficient: 0.6432 - val_jaccard_index: 0.4846\n",
      "Epoch 105/200\n",
      "15/15 [==============================] - 242s 17s/step - loss: 0.0293 - accuracy: 0.8254 - dice_coefficient: 0.6804 - jaccard_index: 0.5170 - val_loss: 0.0703 - val_accuracy: 0.8220 - val_dice_coefficient: 0.6095 - val_jaccard_index: 0.4438\n",
      "Epoch 106/200\n",
      "15/15 [==============================] - 239s 17s/step - loss: 0.0281 - accuracy: 0.8256 - dice_coefficient: 0.6978 - jaccard_index: 0.5373 - val_loss: 0.0595 - val_accuracy: 0.8345 - val_dice_coefficient: 0.6621 - val_jaccard_index: 0.5009\n",
      "Epoch 107/200\n",
      "15/15 [==============================] - 246s 18s/step - loss: 0.0290 - accuracy: 0.8260 - dice_coefficient: 0.6842 - jaccard_index: 0.5230 - val_loss: 0.0780 - val_accuracy: 0.8153 - val_dice_coefficient: 0.6511 - val_jaccard_index: 0.4880\n",
      "Epoch 108/200\n",
      "15/15 [==============================] - 233s 17s/step - loss: 0.0278 - accuracy: 0.8258 - dice_coefficient: 0.7036 - jaccard_index: 0.5455 - val_loss: 0.0676 - val_accuracy: 0.8344 - val_dice_coefficient: 0.6755 - val_jaccard_index: 0.5136\n",
      "Epoch 109/200\n",
      "15/15 [==============================] - 244s 17s/step - loss: 0.0254 - accuracy: 0.8260 - dice_coefficient: 0.7190 - jaccard_index: 0.5632 - val_loss: 0.0577 - val_accuracy: 0.8391 - val_dice_coefficient: 0.6937 - val_jaccard_index: 0.5356\n",
      "Epoch 110/200\n",
      "15/15 [==============================] - 236s 17s/step - loss: 0.0258 - accuracy: 0.8260 - dice_coefficient: 0.7159 - jaccard_index: 0.5590 - val_loss: 0.0909 - val_accuracy: 0.8223 - val_dice_coefficient: 0.6534 - val_jaccard_index: 0.4990\n",
      "Epoch 111/200\n",
      "15/15 [==============================] - 240s 17s/step - loss: 0.0248 - accuracy: 0.8261 - dice_coefficient: 0.7240 - jaccard_index: 0.5698 - val_loss: 0.0883 - val_accuracy: 0.8173 - val_dice_coefficient: 0.6696 - val_jaccard_index: 0.5096\n",
      "Epoch 112/200\n",
      "15/15 [==============================] - 245s 17s/step - loss: 0.0246 - accuracy: 0.8260 - dice_coefficient: 0.7281 - jaccard_index: 0.5744 - val_loss: 0.0401 - val_accuracy: 0.8461 - val_dice_coefficient: 0.6604 - val_jaccard_index: 0.5005\n",
      "Epoch 113/200\n",
      "15/15 [==============================] - 241s 17s/step - loss: 0.0247 - accuracy: 0.8261 - dice_coefficient: 0.7327 - jaccard_index: 0.5804 - val_loss: 0.1007 - val_accuracy: 0.8346 - val_dice_coefficient: 0.6208 - val_jaccard_index: 0.4563\n",
      "Epoch 114/200\n",
      "15/15 [==============================] - 244s 17s/step - loss: 0.0247 - accuracy: 0.8263 - dice_coefficient: 0.7379 - jaccard_index: 0.5869 - val_loss: 0.0871 - val_accuracy: 0.8258 - val_dice_coefficient: 0.6898 - val_jaccard_index: 0.5373\n",
      "Epoch 115/200\n",
      "15/15 [==============================] - 242s 17s/step - loss: 0.0228 - accuracy: 0.8264 - dice_coefficient: 0.7573 - jaccard_index: 0.6108 - val_loss: 0.0933 - val_accuracy: 0.8155 - val_dice_coefficient: 0.6930 - val_jaccard_index: 0.5455\n",
      "Epoch 116/200\n",
      "15/15 [==============================] - 247s 18s/step - loss: 0.0246 - accuracy: 0.8262 - dice_coefficient: 0.7386 - jaccard_index: 0.5871 - val_loss: 0.0389 - val_accuracy: 0.8463 - val_dice_coefficient: 0.6784 - val_jaccard_index: 0.5264\n",
      "Epoch 117/200\n",
      "15/15 [==============================] - 249s 18s/step - loss: 0.0229 - accuracy: 0.8264 - dice_coefficient: 0.7535 - jaccard_index: 0.6065 - val_loss: 0.0939 - val_accuracy: 0.8255 - val_dice_coefficient: 0.6898 - val_jaccard_index: 0.5389\n",
      "Epoch 118/200\n",
      "15/15 [==============================] - 239s 17s/step - loss: 0.0236 - accuracy: 0.8264 - dice_coefficient: 0.7507 - jaccard_index: 0.6020 - val_loss: 0.0858 - val_accuracy: 0.8171 - val_dice_coefficient: 0.7046 - val_jaccard_index: 0.5524\n",
      "Epoch 119/200\n",
      "15/15 [==============================] - 237s 17s/step - loss: 0.0234 - accuracy: 0.8265 - dice_coefficient: 0.7442 - jaccard_index: 0.5950 - val_loss: 0.0904 - val_accuracy: 0.8226 - val_dice_coefficient: 0.6944 - val_jaccard_index: 0.5395\n",
      "Epoch 120/200\n",
      "15/15 [==============================] - 244s 17s/step - loss: 0.0213 - accuracy: 0.8266 - dice_coefficient: 0.7759 - jaccard_index: 0.6353 - val_loss: 0.0473 - val_accuracy: 0.8461 - val_dice_coefficient: 0.6930 - val_jaccard_index: 0.5377\n",
      "Epoch 121/200\n",
      "15/15 [==============================] - 241s 17s/step - loss: 0.0227 - accuracy: 0.8264 - dice_coefficient: 0.7582 - jaccard_index: 0.6123 - val_loss: 0.0649 - val_accuracy: 0.8229 - val_dice_coefficient: 0.6717 - val_jaccard_index: 0.5112\n",
      "Epoch 122/200\n",
      "15/15 [==============================] - 240s 17s/step - loss: 0.0220 - accuracy: 0.8265 - dice_coefficient: 0.7672 - jaccard_index: 0.6239 - val_loss: 0.0928 - val_accuracy: 0.8351 - val_dice_coefficient: 0.6728 - val_jaccard_index: 0.5180\n",
      "Epoch 123/200\n",
      "15/15 [==============================] - 244s 17s/step - loss: 0.0212 - accuracy: 0.8266 - dice_coefficient: 0.7683 - jaccard_index: 0.6252 - val_loss: 0.0596 - val_accuracy: 0.8400 - val_dice_coefficient: 0.7610 - val_jaccard_index: 0.6145\n",
      "Epoch 124/200\n",
      "15/15 [==============================] - 248s 18s/step - loss: 0.0195 - accuracy: 0.8268 - dice_coefficient: 0.7972 - jaccard_index: 0.6637 - val_loss: 0.0820 - val_accuracy: 0.8349 - val_dice_coefficient: 0.6839 - val_jaccard_index: 0.5296\n",
      "Epoch 125/200\n",
      "15/15 [==============================] - 237s 17s/step - loss: 0.0194 - accuracy: 0.8267 - dice_coefficient: 0.7937 - jaccard_index: 0.6594 - val_loss: 0.0984 - val_accuracy: 0.8178 - val_dice_coefficient: 0.7161 - val_jaccard_index: 0.5680\n",
      "Epoch 126/200\n",
      "15/15 [==============================] - 235s 17s/step - loss: 0.0192 - accuracy: 0.8268 - dice_coefficient: 0.7914 - jaccard_index: 0.6567 - val_loss: 0.0715 - val_accuracy: 0.8403 - val_dice_coefficient: 0.7678 - val_jaccard_index: 0.6251\n",
      "Epoch 127/200\n",
      "15/15 [==============================] - 243s 17s/step - loss: 0.0192 - accuracy: 0.8268 - dice_coefficient: 0.7977 - jaccard_index: 0.6655 - val_loss: 0.1060 - val_accuracy: 0.8251 - val_dice_coefficient: 0.6759 - val_jaccard_index: 0.5226\n",
      "Epoch 128/200\n",
      "15/15 [==============================] - 241s 17s/step - loss: 0.0191 - accuracy: 0.8269 - dice_coefficient: 0.7994 - jaccard_index: 0.6673 - val_loss: 0.1092 - val_accuracy: 0.8251 - val_dice_coefficient: 0.7356 - val_jaccard_index: 0.5854\n",
      "Epoch 129/200\n",
      "15/15 [==============================] - 247s 18s/step - loss: 0.0185 - accuracy: 0.8267 - dice_coefficient: 0.8041 - jaccard_index: 0.6742 - val_loss: 0.1112 - val_accuracy: 0.8355 - val_dice_coefficient: 0.6956 - val_jaccard_index: 0.5426\n",
      "Epoch 130/200\n",
      "15/15 [==============================] - 239s 17s/step - loss: 0.0213 - accuracy: 0.8267 - dice_coefficient: 0.7724 - jaccard_index: 0.6313 - val_loss: 0.0983 - val_accuracy: 0.8225 - val_dice_coefficient: 0.6930 - val_jaccard_index: 0.5369\n",
      "Epoch 131/200\n",
      "15/15 [==============================] - 247s 18s/step - loss: 0.0224 - accuracy: 0.8263 - dice_coefficient: 0.7660 - jaccard_index: 0.6221 - val_loss: 0.0712 - val_accuracy: 0.8340 - val_dice_coefficient: 0.6951 - val_jaccard_index: 0.5400\n",
      "Epoch 132/200\n",
      "15/15 [==============================] - 242s 17s/step - loss: 0.0231 - accuracy: 0.8266 - dice_coefficient: 0.7566 - jaccard_index: 0.6099 - val_loss: 0.0899 - val_accuracy: 0.8176 - val_dice_coefficient: 0.7256 - val_jaccard_index: 0.5730\n",
      "Epoch 133/200\n",
      "15/15 [==============================] - 241s 17s/step - loss: 0.0213 - accuracy: 0.8266 - dice_coefficient: 0.7663 - jaccard_index: 0.6230 - val_loss: 0.0825 - val_accuracy: 0.8396 - val_dice_coefficient: 0.7593 - val_jaccard_index: 0.6141\n",
      "Epoch 134/200\n",
      "15/15 [==============================] - 238s 17s/step - loss: 0.0181 - accuracy: 0.8269 - dice_coefficient: 0.8049 - jaccard_index: 0.6754 - val_loss: 0.0985 - val_accuracy: 0.8180 - val_dice_coefficient: 0.7415 - val_jaccard_index: 0.5946\n",
      "Epoch 135/200\n",
      "15/15 [==============================] - 247s 18s/step - loss: 0.0174 - accuracy: 0.8269 - dice_coefficient: 0.8112 - jaccard_index: 0.6841 - val_loss: 0.1154 - val_accuracy: 0.8263 - val_dice_coefficient: 0.6950 - val_jaccard_index: 0.5454\n",
      "Epoch 136/200\n",
      "15/15 [==============================] - 243s 17s/step - loss: 0.0177 - accuracy: 0.8269 - dice_coefficient: 0.8072 - jaccard_index: 0.6785 - val_loss: 0.0747 - val_accuracy: 0.8254 - val_dice_coefficient: 0.7336 - val_jaccard_index: 0.5822\n",
      "Epoch 137/200\n",
      "15/15 [==============================] - 244s 17s/step - loss: 0.0158 - accuracy: 0.8271 - dice_coefficient: 0.8234 - jaccard_index: 0.7009 - val_loss: 0.0970 - val_accuracy: 0.8179 - val_dice_coefficient: 0.7387 - val_jaccard_index: 0.5923\n",
      "Epoch 138/200\n",
      "15/15 [==============================] - 245s 17s/step - loss: 0.0149 - accuracy: 0.8272 - dice_coefficient: 0.8363 - jaccard_index: 0.7205 - val_loss: 0.0935 - val_accuracy: 0.8259 - val_dice_coefficient: 0.7363 - val_jaccard_index: 0.5894\n",
      "Epoch 139/200\n",
      "15/15 [==============================] - 244s 17s/step - loss: 0.0145 - accuracy: 0.8272 - dice_coefficient: 0.8388 - jaccard_index: 0.7238 - val_loss: 0.1099 - val_accuracy: 0.8265 - val_dice_coefficient: 0.7329 - val_jaccard_index: 0.5886\n",
      "Epoch 140/200\n",
      "15/15 [==============================] - 242s 17s/step - loss: 0.0136 - accuracy: 0.8272 - dice_coefficient: 0.8408 - jaccard_index: 0.7266 - val_loss: 0.1159 - val_accuracy: 0.8359 - val_dice_coefficient: 0.7521 - val_jaccard_index: 0.6104\n",
      "Epoch 141/200\n",
      "15/15 [==============================] - 241s 17s/step - loss: 0.0138 - accuracy: 0.8271 - dice_coefficient: 0.8476 - jaccard_index: 0.7368 - val_loss: 0.1100 - val_accuracy: 0.8185 - val_dice_coefficient: 0.7431 - val_jaccard_index: 0.5938\n",
      "Epoch 142/200\n",
      "15/15 [==============================] - 242s 17s/step - loss: 0.0137 - accuracy: 0.8273 - dice_coefficient: 0.8487 - jaccard_index: 0.7388 - val_loss: 0.0794 - val_accuracy: 0.8172 - val_dice_coefficient: 0.7461 - val_jaccard_index: 0.5997\n",
      "Epoch 143/200\n",
      "15/15 [==============================] - 235s 17s/step - loss: 0.0138 - accuracy: 0.8272 - dice_coefficient: 0.8439 - jaccard_index: 0.7313 - val_loss: 0.0972 - val_accuracy: 0.8237 - val_dice_coefficient: 0.7592 - val_jaccard_index: 0.6131\n",
      "Epoch 144/200\n",
      "15/15 [==============================] - 242s 17s/step - loss: 0.0131 - accuracy: 0.8272 - dice_coefficient: 0.8500 - jaccard_index: 0.7401 - val_loss: 0.1263 - val_accuracy: 0.8175 - val_dice_coefficient: 0.7327 - val_jaccard_index: 0.5844\n",
      "Epoch 145/200\n",
      "15/15 [==============================] - 239s 17s/step - loss: 0.0181 - accuracy: 0.8268 - dice_coefficient: 0.8162 - jaccard_index: 0.6916 - val_loss: 0.0874 - val_accuracy: 0.8401 - val_dice_coefficient: 0.7478 - val_jaccard_index: 0.5990\n",
      "Epoch 146/200\n",
      "15/15 [==============================] - 242s 17s/step - loss: 0.0158 - accuracy: 0.8271 - dice_coefficient: 0.8275 - jaccard_index: 0.7080 - val_loss: 0.0759 - val_accuracy: 0.8184 - val_dice_coefficient: 0.7551 - val_jaccard_index: 0.6149\n",
      "Epoch 147/200\n",
      "15/15 [==============================] - 243s 17s/step - loss: 0.0143 - accuracy: 0.8272 - dice_coefficient: 0.8440 - jaccard_index: 0.7322 - val_loss: 0.0833 - val_accuracy: 0.8168 - val_dice_coefficient: 0.7458 - val_jaccard_index: 0.6066\n",
      "Epoch 148/200\n",
      "15/15 [==============================] - 238s 17s/step - loss: 0.0129 - accuracy: 0.8273 - dice_coefficient: 0.8494 - jaccard_index: 0.7392 - val_loss: 0.1182 - val_accuracy: 0.8359 - val_dice_coefficient: 0.7355 - val_jaccard_index: 0.5904\n",
      "Epoch 149/200\n",
      "15/15 [==============================] - 243s 17s/step - loss: 0.0112 - accuracy: 0.8273 - dice_coefficient: 0.8580 - jaccard_index: 0.7531 - val_loss: 0.0829 - val_accuracy: 0.8187 - val_dice_coefficient: 0.7739 - val_jaccard_index: 0.6363\n",
      "Epoch 150/200\n",
      "15/15 [==============================] - 240s 17s/step - loss: 0.0110 - accuracy: 0.8273 - dice_coefficient: 0.8675 - jaccard_index: 0.7672 - val_loss: 0.0828 - val_accuracy: 0.8364 - val_dice_coefficient: 0.7457 - val_jaccard_index: 0.5997\n",
      "Epoch 151/200\n",
      "15/15 [==============================] - 245s 18s/step - loss: 0.0133 - accuracy: 0.8272 - dice_coefficient: 0.8517 - jaccard_index: 0.7440 - val_loss: 0.0395 - val_accuracy: 0.8473 - val_dice_coefficient: 0.7232 - val_jaccard_index: 0.5720\n",
      "Epoch 152/200\n",
      "15/15 [==============================] - 244s 17s/step - loss: 0.0129 - accuracy: 0.8273 - dice_coefficient: 0.8476 - jaccard_index: 0.7368 - val_loss: 0.1545 - val_accuracy: 0.8166 - val_dice_coefficient: 0.7318 - val_jaccard_index: 0.5887\n",
      "Epoch 153/200\n",
      "15/15 [==============================] - 239s 17s/step - loss: 0.0115 - accuracy: 0.8273 - dice_coefficient: 0.8637 - jaccard_index: 0.7611 - val_loss: 0.0730 - val_accuracy: 0.8363 - val_dice_coefficient: 0.7640 - val_jaccard_index: 0.6276\n",
      "Epoch 154/200\n",
      "15/15 [==============================] - 242s 17s/step - loss: 0.0098 - accuracy: 0.8274 - dice_coefficient: 0.8725 - jaccard_index: 0.7748 - val_loss: 0.0870 - val_accuracy: 0.8186 - val_dice_coefficient: 0.7780 - val_jaccard_index: 0.6391\n",
      "Epoch 155/200\n",
      "15/15 [==============================] - 243s 17s/step - loss: 0.0132 - accuracy: 0.8273 - dice_coefficient: 0.8446 - jaccard_index: 0.7323 - val_loss: 0.1011 - val_accuracy: 0.8264 - val_dice_coefficient: 0.7458 - val_jaccard_index: 0.6005\n",
      "Epoch 156/200\n",
      "15/15 [==============================] - 238s 17s/step - loss: 0.0113 - accuracy: 0.8273 - dice_coefficient: 0.8500 - jaccard_index: 0.7415 - val_loss: 0.1005 - val_accuracy: 0.8182 - val_dice_coefficient: 0.7543 - val_jaccard_index: 0.6131\n",
      "Epoch 157/200\n",
      "15/15 [==============================] - 246s 18s/step - loss: 0.0093 - accuracy: 0.8273 - dice_coefficient: 0.8664 - jaccard_index: 0.7662 - val_loss: 0.1128 - val_accuracy: 0.8236 - val_dice_coefficient: 0.7615 - val_jaccard_index: 0.6239\n",
      "Epoch 158/200\n",
      "15/15 [==============================] - 247s 18s/step - loss: 0.0092 - accuracy: 0.8273 - dice_coefficient: 0.8617 - jaccard_index: 0.7586 - val_loss: 0.1086 - val_accuracy: 0.8272 - val_dice_coefficient: 0.7702 - val_jaccard_index: 0.6300\n",
      "Epoch 159/200\n",
      "15/15 [==============================] - 241s 17s/step - loss: 0.0081 - accuracy: 0.8273 - dice_coefficient: 0.8610 - jaccard_index: 0.7575 - val_loss: 0.1034 - val_accuracy: 0.8180 - val_dice_coefficient: 0.7565 - val_jaccard_index: 0.6172\n",
      "Epoch 160/200\n",
      "15/15 [==============================] - 243s 17s/step - loss: 0.0115 - accuracy: 0.8272 - dice_coefficient: 0.8553 - jaccard_index: 0.7484 - val_loss: 0.1331 - val_accuracy: 0.8180 - val_dice_coefficient: 0.7469 - val_jaccard_index: 0.6022\n",
      "Epoch 161/200\n",
      "15/15 [==============================] - 249s 18s/step - loss: 0.0100 - accuracy: 0.8270 - dice_coefficient: 0.8515 - jaccard_index: 0.7431 - val_loss: 0.1167 - val_accuracy: 0.8266 - val_dice_coefficient: 0.7529 - val_jaccard_index: 0.6113\n",
      "Epoch 162/200\n",
      "15/15 [==============================] - 244s 17s/step - loss: 0.0096 - accuracy: 0.8269 - dice_coefficient: 0.8407 - jaccard_index: 0.7272 - val_loss: 0.0957 - val_accuracy: 0.8400 - val_dice_coefficient: 0.7775 - val_jaccard_index: 0.6370\n",
      "Epoch 163/200\n",
      "15/15 [==============================] - 242s 17s/step - loss: 0.0252 - accuracy: 0.8267 - dice_coefficient: 0.7937 - jaccard_index: 0.6640 - val_loss: 0.0844 - val_accuracy: 0.8224 - val_dice_coefficient: 0.6765 - val_jaccard_index: 0.5139\n",
      "Epoch 164/200\n",
      "15/15 [==============================] - 240s 17s/step - loss: 0.0278 - accuracy: 0.8262 - dice_coefficient: 0.7340 - jaccard_index: 0.5828 - val_loss: 0.1440 - val_accuracy: 0.8178 - val_dice_coefficient: 0.7076 - val_jaccard_index: 0.5509\n",
      "Epoch 165/200\n",
      "15/15 [==============================] - 244s 17s/step - loss: 0.0227 - accuracy: 0.8268 - dice_coefficient: 0.7664 - jaccard_index: 0.6240 - val_loss: 0.0581 - val_accuracy: 0.8398 - val_dice_coefficient: 0.7335 - val_jaccard_index: 0.5837\n",
      "Epoch 166/200\n",
      "15/15 [==============================] - 244s 17s/step - loss: 0.0166 - accuracy: 0.8269 - dice_coefficient: 0.8078 - jaccard_index: 0.6800 - val_loss: 0.1218 - val_accuracy: 0.8260 - val_dice_coefficient: 0.7268 - val_jaccard_index: 0.5820\n",
      "Epoch 167/200\n",
      "15/15 [==============================] - 241s 17s/step - loss: 0.0119 - accuracy: 0.8272 - dice_coefficient: 0.8408 - jaccard_index: 0.7277 - val_loss: 0.1236 - val_accuracy: 0.8398 - val_dice_coefficient: 0.7770 - val_jaccard_index: 0.6373\n",
      "Epoch 168/200\n",
      "15/15 [==============================] - 239s 17s/step - loss: 0.0057 - accuracy: 0.8272 - dice_coefficient: 0.8508 - jaccard_index: 0.7423 - val_loss: 0.1668 - val_accuracy: 0.8230 - val_dice_coefficient: 0.7053 - val_jaccard_index: 0.5578\n",
      "Epoch 169/200\n",
      "15/15 [==============================] - 245s 17s/step - loss: 0.0194 - accuracy: 0.8267 - dice_coefficient: 0.7781 - jaccard_index: 0.6396 - val_loss: 0.1141 - val_accuracy: 0.8265 - val_dice_coefficient: 0.7385 - val_jaccard_index: 0.5904\n",
      "Epoch 170/200\n",
      "15/15 [==============================] - 242s 17s/step - loss: 0.0130 - accuracy: 0.8269 - dice_coefficient: 0.8005 - jaccard_index: 0.6714 - val_loss: 0.1467 - val_accuracy: 0.8342 - val_dice_coefficient: 0.6586 - val_jaccard_index: 0.4926\n",
      "Epoch 171/200\n",
      "15/15 [==============================] - 243s 17s/step - loss: 0.0488 - accuracy: 0.8241 - dice_coefficient: 0.6553 - jaccard_index: 0.4964 - val_loss: 0.2099 - val_accuracy: 0.8089 - val_dice_coefficient: 0.3523 - val_jaccard_index: 0.2179\n",
      "Epoch 172/200\n",
      "15/15 [==============================] - 245s 17s/step - loss: 0.0670 - accuracy: 0.8227 - dice_coefficient: 0.4030 - jaccard_index: 0.2538 - val_loss: 0.0840 - val_accuracy: 0.8157 - val_dice_coefficient: 0.5251 - val_jaccard_index: 0.3599\n",
      "Epoch 173/200\n",
      "15/15 [==============================] - 246s 18s/step - loss: 0.0431 - accuracy: 0.8256 - dice_coefficient: 0.5580 - jaccard_index: 0.3899 - val_loss: 0.1089 - val_accuracy: 0.8172 - val_dice_coefficient: 0.6458 - val_jaccard_index: 0.4801\n",
      "Epoch 174/200\n",
      "15/15 [==============================] - 244s 17s/step - loss: 0.0357 - accuracy: 0.8261 - dice_coefficient: 0.6464 - jaccard_index: 0.4811 - val_loss: 0.0647 - val_accuracy: 0.8175 - val_dice_coefficient: 0.6432 - val_jaccard_index: 0.4812\n",
      "Epoch 175/200\n",
      "15/15 [==============================] - 239s 17s/step - loss: 0.0306 - accuracy: 0.8265 - dice_coefficient: 0.6933 - jaccard_index: 0.5359 - val_loss: 0.0674 - val_accuracy: 0.8255 - val_dice_coefficient: 0.6486 - val_jaccard_index: 0.4905\n",
      "Epoch 176/200\n",
      "15/15 [==============================] - 241s 17s/step - loss: 0.0255 - accuracy: 0.8268 - dice_coefficient: 0.7243 - jaccard_index: 0.5731 - val_loss: 0.0814 - val_accuracy: 0.8264 - val_dice_coefficient: 0.6675 - val_jaccard_index: 0.5120\n",
      "Epoch 177/200\n",
      "15/15 [==============================] - 245s 18s/step - loss: 0.0256 - accuracy: 0.8266 - dice_coefficient: 0.7424 - jaccard_index: 0.5921 - val_loss: 0.0862 - val_accuracy: 0.8218 - val_dice_coefficient: 0.6476 - val_jaccard_index: 0.4875\n",
      "Epoch 178/200\n",
      "15/15 [==============================] - 242s 17s/step - loss: 0.0245 - accuracy: 0.8268 - dice_coefficient: 0.7390 - jaccard_index: 0.5897 - val_loss: 0.0938 - val_accuracy: 0.8169 - val_dice_coefficient: 0.7271 - val_jaccard_index: 0.5759\n",
      "Epoch 179/200\n",
      "15/15 [==============================] - 243s 17s/step - loss: 0.0214 - accuracy: 0.8270 - dice_coefficient: 0.7732 - jaccard_index: 0.6322 - val_loss: 0.0709 - val_accuracy: 0.8238 - val_dice_coefficient: 0.7296 - val_jaccard_index: 0.5759\n",
      "Epoch 180/200\n",
      "15/15 [==============================] - 239s 17s/step - loss: 0.0201 - accuracy: 0.8271 - dice_coefficient: 0.7915 - jaccard_index: 0.6563 - val_loss: 0.0760 - val_accuracy: 0.8353 - val_dice_coefficient: 0.7050 - val_jaccard_index: 0.5507\n",
      "Epoch 181/200\n",
      "15/15 [==============================] - 244s 17s/step - loss: 0.0183 - accuracy: 0.8272 - dice_coefficient: 0.7963 - jaccard_index: 0.6640 - val_loss: 0.0793 - val_accuracy: 0.8264 - val_dice_coefficient: 0.7321 - val_jaccard_index: 0.5872\n",
      "Epoch 182/200\n",
      "15/15 [==============================] - 241s 17s/step - loss: 0.0188 - accuracy: 0.8272 - dice_coefficient: 0.7941 - jaccard_index: 0.6595 - val_loss: 0.0857 - val_accuracy: 0.8260 - val_dice_coefficient: 0.7045 - val_jaccard_index: 0.5568\n",
      "Epoch 183/200\n",
      "15/15 [==============================] - 244s 17s/step - loss: 0.0166 - accuracy: 0.8272 - dice_coefficient: 0.8255 - jaccard_index: 0.7043 - val_loss: 0.0581 - val_accuracy: 0.8189 - val_dice_coefficient: 0.7388 - val_jaccard_index: 0.5890\n",
      "Epoch 184/200\n",
      "15/15 [==============================] - 242s 17s/step - loss: 0.0172 - accuracy: 0.8272 - dice_coefficient: 0.7925 - jaccard_index: 0.6592 - val_loss: 0.0615 - val_accuracy: 0.8362 - val_dice_coefficient: 0.7327 - val_jaccard_index: 0.5876\n",
      "Epoch 185/200\n",
      "15/15 [==============================] - 241s 17s/step - loss: 0.0150 - accuracy: 0.8272 - dice_coefficient: 0.8252 - jaccard_index: 0.7039 - val_loss: 0.0596 - val_accuracy: 0.8400 - val_dice_coefficient: 0.7404 - val_jaccard_index: 0.5941\n",
      "Epoch 186/200\n",
      "15/15 [==============================] - 238s 17s/step - loss: 0.0146 - accuracy: 0.8273 - dice_coefficient: 0.8202 - jaccard_index: 0.6971 - val_loss: 0.0815 - val_accuracy: 0.8348 - val_dice_coefficient: 0.7085 - val_jaccard_index: 0.5496\n",
      "Epoch 187/200\n",
      "15/15 [==============================] - 246s 18s/step - loss: 0.0126 - accuracy: 0.8272 - dice_coefficient: 0.8277 - jaccard_index: 0.7076 - val_loss: 0.0741 - val_accuracy: 0.8358 - val_dice_coefficient: 0.7411 - val_jaccard_index: 0.5950\n",
      "Epoch 188/200\n",
      "15/15 [==============================] - 239s 17s/step - loss: 0.0063 - accuracy: 0.8270 - dice_coefficient: 0.8201 - jaccard_index: 0.6967 - val_loss: 0.1277 - val_accuracy: 0.8184 - val_dice_coefficient: 0.7411 - val_jaccard_index: 0.5902\n",
      "Epoch 189/200\n",
      "15/15 [==============================] - 241s 17s/step - loss: 0.6977 - accuracy: 0.8246 - dice_coefficient: 0.5393 - jaccard_index: 0.4321 - val_loss: 5.3793 - val_accuracy: 0.7902 - val_dice_coefficient: 0.0054 - val_jaccard_index: 0.0027\n",
      "Epoch 190/200\n",
      "15/15 [==============================] - 244s 17s/step - loss: 50.7834 - accuracy: 0.7000 - dice_coefficient: 0.0262 - jaccard_index: 0.0135 - val_loss: 0.2077 - val_accuracy: 0.8133 - val_dice_coefficient: 0.0070 - val_jaccard_index: 0.0035\n",
      "Epoch 191/200\n",
      "15/15 [==============================] - 244s 17s/step - loss: 0.2513 - accuracy: 0.8192 - dice_coefficient: 0.0293 - jaccard_index: 0.0150 - val_loss: 0.1808 - val_accuracy: 0.8103 - val_dice_coefficient: 0.0439 - val_jaccard_index: 0.0225\n",
      "Epoch 192/200\n",
      "15/15 [==============================] - 245s 17s/step - loss: 0.1462 - accuracy: 0.8194 - dice_coefficient: 0.0271 - jaccard_index: 0.0138 - val_loss: 0.1810 - val_accuracy: 0.8125 - val_dice_coefficient: 0.0156 - val_jaccard_index: 0.0078\n",
      "Epoch 193/200\n",
      "15/15 [==============================] - 240s 17s/step - loss: 0.1415 - accuracy: 0.8194 - dice_coefficient: 0.0236 - jaccard_index: 0.0119 - val_loss: 0.1691 - val_accuracy: 0.8048 - val_dice_coefficient: 0.0300 - val_jaccard_index: 0.0152\n",
      "Epoch 194/200\n",
      "15/15 [==============================] - 241s 17s/step - loss: 0.1364 - accuracy: 0.8194 - dice_coefficient: 0.0241 - jaccard_index: 0.0122 - val_loss: 0.1557 - val_accuracy: 0.8238 - val_dice_coefficient: 0.0244 - val_jaccard_index: 0.0123\n",
      "Epoch 195/200\n",
      "15/15 [==============================] - 243s 17s/step - loss: 0.1362 - accuracy: 0.8194 - dice_coefficient: 0.0231 - jaccard_index: 0.0117 - val_loss: 0.1628 - val_accuracy: 0.8108 - val_dice_coefficient: 0.0299 - val_jaccard_index: 0.0152\n",
      "Epoch 196/200\n",
      "15/15 [==============================] - 241s 17s/step - loss: 0.1364 - accuracy: 0.8194 - dice_coefficient: 0.0280 - jaccard_index: 0.0142 - val_loss: 0.1659 - val_accuracy: 0.8125 - val_dice_coefficient: 0.0265 - val_jaccard_index: 0.0134\n",
      "Epoch 197/200\n",
      "15/15 [==============================] - 247s 18s/step - loss: 0.1366 - accuracy: 0.8194 - dice_coefficient: 0.0220 - jaccard_index: 0.0111 - val_loss: 0.1703 - val_accuracy: 0.8032 - val_dice_coefficient: 0.0276 - val_jaccard_index: 0.0140\n",
      "Epoch 198/200\n",
      "15/15 [==============================] - 240s 17s/step - loss: 0.1365 - accuracy: 0.8194 - dice_coefficient: 0.0269 - jaccard_index: 0.0137 - val_loss: 0.1661 - val_accuracy: 0.8125 - val_dice_coefficient: 0.0268 - val_jaccard_index: 0.0136\n",
      "Epoch 199/200\n",
      "15/15 [==============================] - 240s 17s/step - loss: 0.1357 - accuracy: 0.8194 - dice_coefficient: 0.0230 - jaccard_index: 0.0116 - val_loss: 0.1634 - val_accuracy: 0.8108 - val_dice_coefficient: 0.0262 - val_jaccard_index: 0.0133\n",
      "Epoch 200/200\n",
      "15/15 [==============================] - 249s 18s/step - loss: 0.1359 - accuracy: 0.8194 - dice_coefficient: 0.0270 - jaccard_index: 0.0137 - val_loss: 0.1632 - val_accuracy: 0.8108 - val_dice_coefficient: 0.0279 - val_jaccard_index: 0.0142\n",
      "5/5 [==============================] - 122s 30s/step - loss: 0.1284 - accuracy: 0.8844 - dice_coefficient: 0.0236 - jaccard_index: 0.0120\n",
      "Test Loss: 0.12844780087471008\n",
      "Test Accuracy: 0.8843837976455688\n",
      "Test Dice Coefficient: 0.02359904535114765\n",
      "Test Jaccard Index: 0.01195440161973238\n"
     ]
    }
   ],
   "source": [
    "# Function to load NIfTI files with memory mapping\n",
    "def load_nifti_memmap(file_path):\n",
    "    img = nib.load(file_path)\n",
    "    data = img.get_fdata(dtype=np.float32, caching='unchanged')  # Memory-mapped array\n",
    "    affine = img.affine\n",
    "    header = img.header\n",
    "    return data, affine, header\n",
    "\n",
    "# Generator function to load data in batches\n",
    "def data_generator(file_list, data_path, mask_path, batch_size, target_shape=None):\n",
    "    while True:\n",
    "        np.random.shuffle(file_list)\n",
    "        for start in range(0, len(file_list), batch_size):\n",
    "            end = min(start + batch_size, len(file_list))\n",
    "            batch_files = file_list[start:end]\n",
    "            \n",
    "            X_batch = []\n",
    "            y_batch = []\n",
    "            \n",
    "            for filename in batch_files:\n",
    "                img_path = os.path.join(data_path, filename)\n",
    "                corresponding_mask_path = os.path.join(mask_path, filename)\n",
    "                \n",
    "                image, _, _ = load_nifti_memmap(img_path)\n",
    "                mask, _, _ = load_nifti_memmap(corresponding_mask_path)\n",
    "                \n",
    "                # Ensure image and mask have the same shape (and possibly resize if needed)\n",
    "                if target_shape:\n",
    "                    image = resize_volume(image, target_shape)\n",
    "                    mask = resize_volume(mask, target_shape)\n",
    "                \n",
    "                X_batch.append(image)\n",
    "                y_batch.append(mask)\n",
    "            \n",
    "            X_batch = np.array(X_batch)[..., np.newaxis]  # Adding channel dimension\n",
    "            y_batch = np.array(y_batch)[..., np.newaxis]  # Adding channel dimension\n",
    "            \n",
    "            yield X_batch, y_batch\n",
    "\n",
    "# Function to resize volumes (if needed)\n",
    "def resize_volume(img, target_shape):\n",
    "    current_shape = img.shape\n",
    "    if current_shape == target_shape:\n",
    "        return img\n",
    "    # Example: using scipy for interpolation\n",
    "    resized_img = scipy.ndimage.zoom(img, (target_shape[0]/current_shape[0], target_shape[1]/current_shape[1], target_shape[2]/current_shape[2]), order=3)\n",
    "    return resized_img\n",
    "\n",
    "def resize_image(image, target_shape):\n",
    "    # Resize the image to match the target shape (height, width)\n",
    "    return resize(image, target_shape, preserve_range=True, anti_aliasing=True)\n",
    "\n",
    "def pad_or_crop_volume(volume, target_shape):\n",
    "    current_shape = volume.shape\n",
    "    \n",
    "    # Calculate padding width for each dimension\n",
    "    pad_width = [(0, max(target_shape[i] - current_shape[i], 0)) for i in range(3)]\n",
    "    \n",
    "    # Pad the volume to the target shape\n",
    "    volume = np.pad(volume, pad_width, mode='constant', constant_values=0)\n",
    "    \n",
    "    # Calculate cropping dimensions for each dimension\n",
    "    crop_start = [(volume.shape[i] - target_shape[i]) // 2 for i in range(3)]\n",
    "    crop_end = [crop_start[i] + target_shape[i] for i in range(3)]\n",
    "    \n",
    "    # Crop the volume to the target shape\n",
    "    slices = [slice(crop_start[i], crop_end[i]) for i in range(3)]\n",
    "    volume = volume[slices[0], slices[1], slices[2]]\n",
    "    \n",
    "    return volume\n",
    "\n",
    "def calculate_volume(mask, voxel_volume):\n",
    "    # Calculate the volume based on the mask\n",
    "    return np.sum(mask) * voxel_volume\n",
    "    \n",
    "def unet_3d(input_shape):\n",
    "    inputs = Input(input_shape)\n",
    "    \n",
    "    # Downsampling\n",
    "    c1 = Conv3D(32, (3, 3, 3), activation='relu', padding='same')(inputs)\n",
    "    c1 = Conv3D(32, (3, 3, 3), activation='relu', padding='same')(c1)\n",
    "    c1 = Conv3D(32, (3, 3, 3), activation='relu', padding='same')(c1)  # Added layer\n",
    "    c1 = Conv3D(32, (3, 3, 3), activation='relu', padding='same')(c1)  # Added layer\n",
    "    p1 = MaxPooling3D((2, 2, 2))(c1)\n",
    "    \n",
    "    c2 = Conv3D(64, (3, 3, 3), activation='relu', padding='same')(p1)\n",
    "    c2 = Conv3D(64, (3, 3, 3), activation='relu', padding='same')(c2)\n",
    "    c2 = Conv3D(64, (3, 3, 3), activation='relu', padding='same')(c2)  # Added layer\n",
    "    c2 = Conv3D(64, (3, 3, 3), activation='relu', padding='same')(c2)  # Added layer\n",
    "    p2 = MaxPooling3D((2, 2, 2))(c2)\n",
    "    \n",
    "    c3 = Conv3D(128, (3, 3, 3), activation='relu', padding='same')(p2)\n",
    "    c3 = Conv3D(128, (3, 3, 3), activation='relu', padding='same')(c3)\n",
    "    c3 = Conv3D(128, (3, 3, 3), activation='relu', padding='same')(c3)  # Added layer\n",
    "    c3 = Conv3D(128, (3, 3, 3), activation='relu', padding='same')(c3)  # Added layer\n",
    "    p3 = MaxPooling3D((2, 2, 2))(c3)\n",
    "    \n",
    "    c4 = Conv3D(256, (3, 3, 3), activation='relu', padding='same')(p3)\n",
    "    c4 = Conv3D(256, (3, 3, 3), activation='relu', padding='same')(c4)\n",
    "    c4 = Conv3D(256, (3, 3, 3), activation='relu', padding='same')(c4)  # Added layer\n",
    "    c4 = Conv3D(256, (3, 3, 3), activation='relu', padding='same')(c4)  # Added layer\n",
    "    \n",
    "    # Upsampling\n",
    "    u5 = UpSampling3D((2, 2, 2))(c4)\n",
    "    u5 = concatenate([u5, c3])\n",
    "    c5 = Conv3D(128, (3, 3, 3), activation='relu', padding='same')(u5)\n",
    "    c5 = Conv3D(128, (3, 3, 3), activation='relu', padding='same')(c5)\n",
    "    c5 = Conv3D(128, (3, 3, 3), activation='relu', padding='same')(c5)  # Added layer\n",
    "    c5 = Conv3D(128, (3, 3, 3), activation='relu', padding='same')(c5)  # Added layer\n",
    "    \n",
    "    u6 = UpSampling3D((2, 2, 2))(c5)\n",
    "    u6 = concatenate([u6, c2])\n",
    "    c6 = Conv3D(64, (3, 3, 3), activation='relu', padding='same')(u6)\n",
    "    c6 = Conv3D(64, (3, 3, 3), activation='relu', padding='same')(c6)\n",
    "    c6 = Conv3D(64, (3, 3, 3), activation='relu', padding='same')(c6)  # Added layer\n",
    "    c6 = Conv3D(64, (3, 3, 3), activation='relu', padding='same')(c6)  # Added layer\n",
    "    \n",
    "    u7 = UpSampling3D((2, 2, 2))(c6)\n",
    "    u7 = concatenate([u7, c1])\n",
    "    c7 = Conv3D(32, (3, 3, 3), activation='relu', padding='same')(u7)\n",
    "    c7 = Conv3D(32, (3, 3, 3), activation='relu', padding='same')(c7)\n",
    "    c7 = Conv3D(32, (3, 3, 3), activation='relu', padding='same')(c7)  # Added layer\n",
    "    c7 = Conv3D(32, (3, 3, 3), activation='relu', padding='same')(c7)  # Added layer\n",
    "\n",
    "    outputs = Conv3D(1, (1, 1, 1), activation='sigmoid')(c7)\n",
    "    \n",
    "    return Model(inputs, outputs)\n",
    "\n",
    "    model = Model(inputs=[inputs], outputs=[outputs])\n",
    "    return model\n",
    "    \n",
    "    model = Model(inputs, outputs)\n",
    "    #model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy', dice_coefficient, jaccard_index])\n",
    "    return model\n",
    "\n",
    "# Dice coefficient\n",
    "def dice_coefficient(y_true, y_pred):\n",
    "    y_true_f = tf.keras.backend.flatten(y_true)\n",
    "    y_pred_f = tf.keras.backend.flatten(y_pred)\n",
    "    intersection = tf.keras.backend.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + 1) / (tf.keras.backend.sum(y_true_f) + tf.keras.backend.sum(y_pred_f) + 1)\n",
    "\n",
    "# Jaccard index\n",
    "def jaccard_index(y_true, y_pred):\n",
    "    y_true_f = tf.keras.backend.flatten(y_true)\n",
    "    y_pred_f = tf.keras.backend.flatten(y_pred)\n",
    "    intersection = tf.keras.backend.sum(y_true_f * y_pred_f)\n",
    "    return (intersection + 1) / (tf.keras.backend.sum(y_true_f) + tf.keras.backend.sum(y_pred_f) - intersection + 1)\n",
    "\n",
    "# Example paths (update these to your dataset paths)\n",
    "data_path = r'/home/icmr/Documents/DATASET/MSD_LIVER/Portal/Train/imageTr'  # Update with the correct path\n",
    "mask_path = r'/home/icmr/Documents/DATASET/MSD_LIVER/Portal/Train/LabelTr'  # Update with the correct path\n",
    "\n",
    "# Verify paths exist\n",
    "if not os.path.exists(data_path):\n",
    "    raise FileNotFoundError(f\"Data path not found: {data_path}\")\n",
    "if not os.path.exists(mask_path):\n",
    "    raise FileNotFoundError(f\"Mask path not found: {mask_path}\")\n",
    "\n",
    "# List of files\n",
    "file_list = [filename for filename in os.listdir(data_path) if filename.endswith('.nii.gz')]\n",
    "#file_list_test = \n",
    "# Split the dataset\n",
    "train_val_files, test_files = train_test_split(file_list, test_size=0.2, random_state=42)\n",
    "train_files, val_files = train_test_split(train_val_files, test_size=0.25, random_state=42)  # 0.25 * 0.8 = 0.2\n",
    "\n",
    "# Define and compile the model\n",
    "input_shape = (128, 128, 64, 1)  # Example input shape, adjust accordingly\n",
    "model = unet_3d(input_shape)\n",
    "model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy', dice_coefficient, jaccard_index])\n",
    "  \n",
    "# Define callbacks\n",
    "checkpoint = ModelCheckpoint('unet3d_best_model.h5', save_best_only=True, monitor='val_loss', mode='min')\n",
    "#early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# Define batch size\n",
    "batch_size = 2\n",
    "\n",
    "# Create data generators\n",
    "train_generator = data_generator(train_files, data_path, mask_path, batch_size, target_shape=input_shape[:3])\n",
    "val_generator = data_generator(val_files, data_path, mask_path, batch_size, target_shape=input_shape[:3])\n",
    "test_generator = data_generator(test_files, data_path, mask_path, batch_size, target_shape=input_shape[:3])\n",
    "\n",
    "# Calculate steps per epoch\n",
    "steps_per_epoch = len(train_files) // batch_size\n",
    "validation_steps = len(val_files) // batch_size\n",
    "test_steps = len(test_files) // batch_size\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(train_generator, validation_data=val_generator, epochs=200, steps_per_epoch=steps_per_epoch, validation_steps=validation_steps, callbacks=[checkpoint])\n",
    "\n",
    "# Save the model\n",
    "model.save('unet3d_model.h5')\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_accuracy, test_dice, test_jaccard = model.evaluate(test_generator, steps=test_steps)\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")\n",
    "print(f\"Test Dice Coefficient: {test_dice}\")\n",
    "print(f\"Test Jaccard Index: {test_jaccard}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load necessary libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import scipy.ndimage\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras.layers import Input, Conv3D, MaxPooling3D, UpSampling3D, concatenate\n",
    "import tensorflow as tf\n",
    "\n",
    "# Load saved model\n",
    "saved_model_path = 'unet3d_model.h5'\n",
    "if not os.path.exists(saved_model_path):\n",
    "    raise FileNotFoundError(f\"Saved model file not found: {saved_model_path}\")\n",
    "\n",
    "# Load the pre-trained model\n",
    "model = load_model(saved_model_path, \n",
    "                   custom_objects={'dice_coefficient': dice_coefficient, 'jaccard_index': jaccard_index})\n",
    "\n",
    "# Freeze initial layers for transfer learning\n",
    "for layer in model.layers[:len(model.layers) // 2]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Compile the model again after freezing layers\n",
    "model.compile(optimizer=Adam(learning_rate=1e-4), loss='binary_crossentropy', \n",
    "              metrics=['accuracy', dice_coefficient, jaccard_index])\n",
    "\n",
    "# Example paths (update these to your new dataset paths)\n",
    "new_data_path = r'/path/to/new/test/data/images'  # Update with the correct path\n",
    "new_mask_path = r'/path/to/new/test/data/masks'   # Update with the correct path\n",
    "\n",
    "# Verify paths exist\n",
    "if not os.path.exists(new_data_path):\n",
    "    raise FileNotFoundError(f\"New data path not found: {new_data_path}\")\n",
    "if not os.path.exists(new_mask_path):\n",
    "    raise FileNotFoundError(f\"New mask path not found: {new_mask_path}\")\n",
    "\n",
    "# List of new files\n",
    "new_file_list = [filename for filename in os.listdir(new_data_path) if filename.endswith('.nii.gz')]\n",
    "\n",
    "# Split the dataset for testing\n",
    "_, test_files = train_test_split(new_file_list, test_size=1.0, random_state=42)\n",
    "\n",
    "# Define batch size and target shape\n",
    "batch_size = 2\n",
    "target_shape = (128, 128, 64)  # Adjust as necessary\n",
    "\n",
    "def data_generator(file_list, data_path, mask_path, batch_size, target_shape=None):\n",
    "    while True:\n",
    "        np.random.shuffle(file_list)\n",
    "        for start in range(0, len(file_list), batch_size):\n",
    "            end = min(start + batch_size, len(file_list))\n",
    "            batch_files = file_list[start:end]\n",
    "\n",
    "            X_batch = []\n",
    "            y_batch = []\n",
    "\n",
    "            for filename in batch_files:\n",
    "                img_path = os.path.join(data_path, filename)\n",
    "                corresponding_mask_path = os.path.join(mask_path, filename)\n",
    "\n",
    "                image, _, _ = load_nifti_memmap(img_path)\n",
    "                mask, _, _ = load_nifti_memmap(corresponding_mask_path)\n",
    "\n",
    "                # Resize image and mask if needed\n",
    "                if target_shape:\n",
    "                    image = resize_volume(image, target_shape)\n",
    "                    mask = resize_volume(mask, target_shape)\n",
    "\n",
    "                X_batch.append(image)\n",
    "                y_batch.append(mask)\n",
    "\n",
    "            X_batch = np.array(X_batch)[..., np.newaxis]  # Adding channel dimension\n",
    "            y_batch = np.array(y_batch)[..., np.newaxis]  # Adding channel dimension\n",
    "\n",
    "            yield X_batch, y_batch\n",
    "\n",
    "# Create test data generator\n",
    "test_generator = data_generator(test_files, new_data_path, new_mask_path, batch_size, target_shape=target_shape)\n",
    "\n",
    "test_steps = len(test_files) // batch_size\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_accuracy, test_dice, test_jaccard = model.evaluate(test_generator, steps=test_steps)\n",
    "\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")\n",
    "print(f\"Test Dice Coefficient: {test_dice}\")\n",
    "print(f\"Test Jaccard Index: {test_jaccard}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
