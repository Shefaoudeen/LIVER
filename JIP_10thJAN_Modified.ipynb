{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import nibabel as nib\n",
    "#%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, Callback\n",
    "from skimage.transform import resize\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "import scipy.ndimage\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import (Input, Conv3D, MaxPooling3D, UpSampling3D, concatenate, Add, Dropout)\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow.keras.backend as K\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load NIfTI files with memory mapping\n",
    "def load_nifti_memmap(file_path):\n",
    "    img = nib.load(file_path)\n",
    "    data = img.get_fdata(dtype=np.float32, caching='unchanged')  # Memory-mapped array\n",
    "    affine = img.affine\n",
    "    header = img.header\n",
    "    return data, affine, header\n",
    "\n",
    "# Generator function to load data in batches\n",
    "def data_generator(file_list, data_path, mask_path, batch_size, target_shape=None):\n",
    "    while True:\n",
    "        np.random.shuffle(file_list)\n",
    "        for start in range(0, len(file_list), batch_size):\n",
    "            end = min(start + batch_size, len(file_list))\n",
    "            batch_files = file_list[start:end]\n",
    "            \n",
    "            X_batch = []\n",
    "            y_batch = []\n",
    "            \n",
    "            for filename in batch_files:\n",
    "                img_path = os.path.join(data_path, filename)\n",
    "                corresponding_mask_path = os.path.join(mask_path, filename)\n",
    "                \n",
    "                image, _, _ = load_nifti_memmap(img_path)\n",
    "                mask, _, _ = load_nifti_memmap(corresponding_mask_path)\n",
    "                \n",
    "                # Ensure image and mask have the same shape (and possibly resize if needed)\n",
    "                if target_shape:\n",
    "                    image = resize_volume(image, target_shape)\n",
    "                    mask = resize_volume(mask, target_shape)\n",
    "                \n",
    "                X_batch.append(image)\n",
    "                y_batch.append(mask)\n",
    "            \n",
    "            X_batch = np.array(X_batch)[..., np.newaxis]  # Adding channel dimension\n",
    "            y_batch = np.array(y_batch)[..., np.newaxis]  # Adding channel dimension\n",
    "            \n",
    "            yield X_batch, y_batch\n",
    "\n",
    "# Function to resize volumes (if needed)\n",
    "def resize_volume(img, target_shape):\n",
    "    current_shape = img.shape\n",
    "    if current_shape == target_shape:\n",
    "        return img\n",
    "    # Example: using scipy for interpolation\n",
    "    resized_img = scipy.ndimage.zoom(img, (target_shape[0]/current_shape[0], target_shape[1]/current_shape[1], target_shape[2]/current_shape[2]), order=3)\n",
    "    return resized_img\n",
    "\n",
    "def resize_image(image, target_shape):\n",
    "    # Resize the image to match the target shape (height, width)\n",
    "    return resize(image, target_shape, preserve_range=True, anti_aliasing=True)\n",
    "\n",
    "def pad_or_crop_volume(volume, target_shape):\n",
    "    current_shape = volume.shape\n",
    "    \n",
    "    # Calculate padding width for each dimension\n",
    "    pad_width = [(0, max(target_shape[i] - current_shape[i], 0)) for i in range(3)]\n",
    "    \n",
    "    # Pad the volume to the target shape\n",
    "    volume = np.pad(volume, pad_width, mode='constant', constant_values=0)\n",
    "    \n",
    "    # Calculate cropping dimensions for each dimension\n",
    "    crop_start = [(volume.shape[i] - target_shape[i]) // 2 for i in range(3)]\n",
    "    crop_end = [crop_start[i] + target_shape[i] for i in range(3)]\n",
    "    \n",
    "    # Crop the volume to the target shape\n",
    "    slices = [slice(crop_start[i], crop_end[i]) for i in range(3)]\n",
    "    volume = volume[slices[0], slices[1], slices[2]]\n",
    "    \n",
    "    return volume\n",
    "\n",
    "def calculate_volume(mask, voxel_volume):\n",
    "    # Calculate the volume based on the mask\n",
    "    return np.sum(mask) * voxel_volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics\n",
    "def dice_similarity(y_true, y_pred):\n",
    "    smooth = 1.0\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "def jaccard_index(y_true, y_pred):\n",
    "    smooth = 1.0\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    union = K.sum(y_true_f) + K.sum(y_pred_f) - intersection\n",
    "    return (intersection + smooth) / (union + smooth)\n",
    "\n",
    "def boundary_f1_score(y_true, y_pred, distance_threshold=1.5):\n",
    "    \"\"\"\n",
    "    Approximate Boundary F1 Score: Measures how well predicted and true boundaries match.\n",
    "    For simplicity, this assumes binary masks and uses Manhattan distance to calculate boundary proximity.\n",
    "    \"\"\"\n",
    "    def boundaries(mask):\n",
    "        \"\"\"Extract boundaries from a binary mask.\"\"\"\n",
    "        edge_x = K.abs(mask[:, 1:, :, :] - mask[:, :-1, :, :])\n",
    "        edge_y = K.abs(mask[:, :, 1:, :] - mask[:, :, :-1, :])\n",
    "        edge_z = K.abs(mask[:, :, :, 1:] - mask[:, :, :, :-1])\n",
    "        return K.clip(edge_x + edge_y + edge_z, 0, 1)\n",
    "    \n",
    "    true_boundary = boundaries(y_true)\n",
    "    pred_boundary = boundaries(y_pred)\n",
    "    \n",
    "    true_positive = K.sum(true_boundary * pred_boundary)\n",
    "    false_positive = K.sum(pred_boundary * (1 - true_boundary))\n",
    "    false_negative = K.sum(true_boundary * (1 - pred_boundary))\n",
    "    \n",
    "    precision = true_positive / (true_positive + false_positive + K.epsilon())\n",
    "    recall = true_positive / (true_positive + false_negative + K.epsilon())\n",
    "    \n",
    "    return 2 * (precision * recall) / (precision + recall + K.epsilon())\n",
    "\n",
    "# Loss Function\n",
    "def dice_loss(y_true, y_pred):\n",
    "    return 1 - dice_similarity(y_true, y_pred)\n",
    "\n",
    "def combined_loss(y_true, y_pred):\n",
    "    bce = tf.keras.losses.BinaryCrossentropy()(y_true, y_pred)\n",
    "    dice = dice_loss(y_true, y_pred)\n",
    "    return bce + dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-21 09:55:53.126044: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43391 MB memory:  -> device: 0, name: NVIDIA RTX A6000, pci bus id: 0000:51:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 128, 128, 200, 1)]   0         []                            \n",
      "                                                                                                  \n",
      " conv3d (Conv3D)             (None, 128, 128, 200, 32)    896       ['input_1[0][0]']             \n",
      "                                                                                                  \n",
      " conv3d_1 (Conv3D)           (None, 128, 128, 200, 32)    27680     ['conv3d[0][0]']              \n",
      "                                                                                                  \n",
      " conv3d_2 (Conv3D)           (None, 128, 128, 200, 32)    64        ['input_1[0][0]']             \n",
      "                                                                                                  \n",
      " add (Add)                   (None, 128, 128, 200, 32)    0         ['conv3d_1[0][0]',            \n",
      "                                                                     'conv3d_2[0][0]']            \n",
      "                                                                                                  \n",
      " max_pooling3d (MaxPooling3  (None, 64, 64, 100, 32)      0         ['add[0][0]']                 \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3d_3 (Conv3D)           (None, 64, 64, 100, 64)      55360     ['max_pooling3d[0][0]']       \n",
      "                                                                                                  \n",
      " conv3d_4 (Conv3D)           (None, 64, 64, 100, 64)      110656    ['conv3d_3[0][0]']            \n",
      "                                                                                                  \n",
      " conv3d_5 (Conv3D)           (None, 64, 64, 100, 64)      2112      ['max_pooling3d[0][0]']       \n",
      "                                                                                                  \n",
      " add_1 (Add)                 (None, 64, 64, 100, 64)      0         ['conv3d_4[0][0]',            \n",
      "                                                                     'conv3d_5[0][0]']            \n",
      "                                                                                                  \n",
      " max_pooling3d_1 (MaxPoolin  (None, 32, 32, 50, 64)       0         ['add_1[0][0]']               \n",
      " g3D)                                                                                             \n",
      "                                                                                                  \n",
      " conv3d_6 (Conv3D)           (None, 32, 32, 50, 128)      221312    ['max_pooling3d_1[0][0]']     \n",
      "                                                                                                  \n",
      " conv3d_7 (Conv3D)           (None, 32, 32, 50, 128)      442496    ['conv3d_6[0][0]']            \n",
      "                                                                                                  \n",
      " conv3d_8 (Conv3D)           (None, 32, 32, 50, 128)      8320      ['max_pooling3d_1[0][0]']     \n",
      "                                                                                                  \n",
      " add_2 (Add)                 (None, 32, 32, 50, 128)      0         ['conv3d_7[0][0]',            \n",
      "                                                                     'conv3d_8[0][0]']            \n",
      "                                                                                                  \n",
      " max_pooling3d_2 (MaxPoolin  (None, 16, 16, 25, 128)      0         ['add_2[0][0]']               \n",
      " g3D)                                                                                             \n",
      "                                                                                                  \n",
      " conv3d_9 (Conv3D)           (None, 16, 16, 25, 256)      884992    ['max_pooling3d_2[0][0]']     \n",
      "                                                                                                  \n",
      " conv3d_10 (Conv3D)          (None, 16, 16, 25, 256)      1769728   ['conv3d_9[0][0]']            \n",
      "                                                                                                  \n",
      " conv3d_11 (Conv3D)          (None, 16, 16, 25, 256)      33024     ['max_pooling3d_2[0][0]']     \n",
      "                                                                                                  \n",
      " add_3 (Add)                 (None, 16, 16, 25, 256)      0         ['conv3d_10[0][0]',           \n",
      "                                                                     'conv3d_11[0][0]']           \n",
      "                                                                                                  \n",
      " dropout (Dropout)           (None, 16, 16, 25, 256)      0         ['add_3[0][0]']               \n",
      "                                                                                                  \n",
      " up_sampling3d (UpSampling3  (None, 32, 32, 50, 256)      0         ['dropout[0][0]']             \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3d_12 (Conv3D)          (None, 32, 32, 50, 128)      32896     ['up_sampling3d[0][0]']       \n",
      "                                                                                                  \n",
      " conv3d_13 (Conv3D)          (None, 32, 32, 50, 128)      16512     ['add_2[0][0]']               \n",
      "                                                                                                  \n",
      " add_4 (Add)                 (None, 32, 32, 50, 128)      0         ['conv3d_12[0][0]',           \n",
      "                                                                     'conv3d_13[0][0]']           \n",
      "                                                                                                  \n",
      " tf.nn.relu (TFOpLambda)     (None, 32, 32, 50, 128)      0         ['add_4[0][0]']               \n",
      "                                                                                                  \n",
      " conv3d_14 (Conv3D)          (None, 32, 32, 50, 1)        129       ['tf.nn.relu[0][0]']          \n",
      "                                                                                                  \n",
      " tf.math.multiply (TFOpLamb  (None, 32, 32, 50, 256)      0         ['up_sampling3d[0][0]',       \n",
      " da)                                                                 'conv3d_14[0][0]']           \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)   (None, 32, 32, 50, 384)      0         ['tf.math.multiply[0][0]',    \n",
      "                                                                     'add_2[0][0]']               \n",
      "                                                                                                  \n",
      " conv3d_15 (Conv3D)          (None, 32, 32, 50, 128)      1327232   ['concatenate[0][0]']         \n",
      "                                                                                                  \n",
      " conv3d_16 (Conv3D)          (None, 32, 32, 50, 128)      442496    ['conv3d_15[0][0]']           \n",
      "                                                                                                  \n",
      " conv3d_17 (Conv3D)          (None, 32, 32, 50, 128)      49280     ['concatenate[0][0]']         \n",
      "                                                                                                  \n",
      " add_5 (Add)                 (None, 32, 32, 50, 128)      0         ['conv3d_16[0][0]',           \n",
      "                                                                     'conv3d_17[0][0]']           \n",
      "                                                                                                  \n",
      " up_sampling3d_1 (UpSamplin  (None, 64, 64, 100, 128)     0         ['add_5[0][0]']               \n",
      " g3D)                                                                                             \n",
      "                                                                                                  \n",
      " conv3d_18 (Conv3D)          (None, 64, 64, 100, 64)      8256      ['up_sampling3d_1[0][0]']     \n",
      "                                                                                                  \n",
      " conv3d_19 (Conv3D)          (None, 64, 64, 100, 64)      4160      ['add_1[0][0]']               \n",
      "                                                                                                  \n",
      " add_6 (Add)                 (None, 64, 64, 100, 64)      0         ['conv3d_18[0][0]',           \n",
      "                                                                     'conv3d_19[0][0]']           \n",
      "                                                                                                  \n",
      " tf.nn.relu_1 (TFOpLambda)   (None, 64, 64, 100, 64)      0         ['add_6[0][0]']               \n",
      "                                                                                                  \n",
      " conv3d_20 (Conv3D)          (None, 64, 64, 100, 1)       65        ['tf.nn.relu_1[0][0]']        \n",
      "                                                                                                  \n",
      " tf.math.multiply_1 (TFOpLa  (None, 64, 64, 100, 128)     0         ['up_sampling3d_1[0][0]',     \n",
      " mbda)                                                               'conv3d_20[0][0]']           \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate  (None, 64, 64, 100, 192)     0         ['tf.math.multiply_1[0][0]',  \n",
      " )                                                                   'add_1[0][0]']               \n",
      "                                                                                                  \n",
      " conv3d_21 (Conv3D)          (None, 64, 64, 100, 64)      331840    ['concatenate_1[0][0]']       \n",
      "                                                                                                  \n",
      " conv3d_22 (Conv3D)          (None, 64, 64, 100, 64)      110656    ['conv3d_21[0][0]']           \n",
      "                                                                                                  \n",
      " conv3d_23 (Conv3D)          (None, 64, 64, 100, 64)      12352     ['concatenate_1[0][0]']       \n",
      "                                                                                                  \n",
      " add_7 (Add)                 (None, 64, 64, 100, 64)      0         ['conv3d_22[0][0]',           \n",
      "                                                                     'conv3d_23[0][0]']           \n",
      "                                                                                                  \n",
      " up_sampling3d_2 (UpSamplin  (None, 128, 128, 200, 64)    0         ['add_7[0][0]']               \n",
      " g3D)                                                                                             \n",
      "                                                                                                  \n",
      " conv3d_24 (Conv3D)          (None, 128, 128, 200, 32)    2080      ['up_sampling3d_2[0][0]']     \n",
      "                                                                                                  \n",
      " conv3d_25 (Conv3D)          (None, 128, 128, 200, 32)    1056      ['add[0][0]']                 \n",
      "                                                                                                  \n",
      " add_8 (Add)                 (None, 128, 128, 200, 32)    0         ['conv3d_24[0][0]',           \n",
      "                                                                     'conv3d_25[0][0]']           \n",
      "                                                                                                  \n",
      " tf.nn.relu_2 (TFOpLambda)   (None, 128, 128, 200, 32)    0         ['add_8[0][0]']               \n",
      "                                                                                                  \n",
      " conv3d_26 (Conv3D)          (None, 128, 128, 200, 1)     33        ['tf.nn.relu_2[0][0]']        \n",
      "                                                                                                  \n",
      " tf.math.multiply_2 (TFOpLa  (None, 128, 128, 200, 64)    0         ['up_sampling3d_2[0][0]',     \n",
      " mbda)                                                               'conv3d_26[0][0]']           \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate  (None, 128, 128, 200, 96)    0         ['tf.math.multiply_2[0][0]',  \n",
      " )                                                                   'add[0][0]']                 \n",
      "                                                                                                  \n",
      " conv3d_27 (Conv3D)          (None, 128, 128, 200, 32)    82976     ['concatenate_2[0][0]']       \n",
      "                                                                                                  \n",
      " conv3d_28 (Conv3D)          (None, 128, 128, 200, 32)    27680     ['conv3d_27[0][0]']           \n",
      "                                                                                                  \n",
      " conv3d_29 (Conv3D)          (None, 128, 128, 200, 32)    3104      ['concatenate_2[0][0]']       \n",
      "                                                                                                  \n",
      " add_9 (Add)                 (None, 128, 128, 200, 32)    0         ['conv3d_28[0][0]',           \n",
      "                                                                     'conv3d_29[0][0]']           \n",
      "                                                                                                  \n",
      " conv3d_30 (Conv3D)          (None, 128, 128, 200, 1)     33        ['add_9[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 6009476 (22.92 MB)\n",
      "Trainable params: 6009476 (22.92 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Attention Block\n",
    "def attention_block(x, g, inter_channel):\n",
    "    theta_x = Conv3D(inter_channel, (1, 1, 1))(x)\n",
    "    phi_g = Conv3D(inter_channel, (1, 1, 1))(g)\n",
    "    add = Add()([theta_x, phi_g])\n",
    "    psi = tf.keras.activations.relu(add)\n",
    "    psi = Conv3D(1, (1, 1, 1), activation='sigmoid')(psi)\n",
    "    return tf.multiply(x, psi)\n",
    "\n",
    "# Residual Block\n",
    "def residual_block(input_tensor, filters):\n",
    "    conv = Conv3D(filters, (3, 3, 3), activation='relu', padding='same')(input_tensor)\n",
    "    conv = Conv3D(filters, (3, 3, 3), activation='relu', padding='same')(conv)\n",
    "    shortcut = Conv3D(filters, (1, 1, 1), padding='same')(input_tensor)\n",
    "    output = Add()([conv, shortcut])\n",
    "    return output\n",
    "\n",
    "# Modified 3D U-Net\n",
    "def unet_3d_modified(input_shape):\n",
    "    inputs = Input(input_shape)\n",
    "    \n",
    "    # Downsampling\n",
    "    c1 = residual_block(inputs, 32)\n",
    "    p1 = MaxPooling3D((2, 2, 2))(c1)\n",
    "    \n",
    "    c2 = residual_block(p1, 64)\n",
    "    p2 = MaxPooling3D((2, 2, 2))(c2)\n",
    "    \n",
    "    c3 = residual_block(p2, 128)\n",
    "    p3 = MaxPooling3D((2, 2, 2))(c3)\n",
    "    \n",
    "    c4 = residual_block(p3, 256)  # Bottleneck\n",
    "    c4 = Dropout(0.3)(c4)  # Dropout for regularization\n",
    "    \n",
    "    # Upsampling\n",
    "    u5 = UpSampling3D((2, 2, 2))(c4)\n",
    "    u5 = attention_block(u5, c3, 128)  # Attention\n",
    "    u5 = concatenate([u5, c3])\n",
    "    c5 = residual_block(u5, 128)\n",
    "    \n",
    "    u6 = UpSampling3D((2, 2, 2))(c5)\n",
    "    u6 = attention_block(u6, c2, 64)  # Attention\n",
    "    u6 = concatenate([u6, c2])\n",
    "    c6 = residual_block(u6, 64)\n",
    "    \n",
    "    u7 = UpSampling3D((2, 2, 2))(c6)\n",
    "    u7 = attention_block(u7, c1, 32)  # Attention\n",
    "    u7 = concatenate([u7, c1])\n",
    "    c7 = residual_block(u7, 32)\n",
    "    \n",
    "    outputs = Conv3D(1, (1, 1, 1), activation='sigmoid')(c7)\n",
    "    \n",
    "    return Model(inputs, outputs)\n",
    "\n",
    "# Dice + BCE Loss Function\n",
    "def dice_loss(y_true, y_pred):\n",
    "    smooth = 1.0\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return 1 - (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "def combined_loss(y_true, y_pred):\n",
    "    bce = tf.keras.losses.BinaryCrossentropy()(y_true, y_pred)\n",
    "    dice = dice_loss(y_true, y_pred)\n",
    "    return bce + dice\n",
    "\n",
    "# Compile the Model\n",
    "input_shape = (128, 128, 200, 1)  # Example input shape\n",
    "model = unet_3d_modified(input_shape)\n",
    "model.compile(optimizer=Adam(learning_rate=1e-4), loss=combined_loss, metrics=['accuracy', dice_similarity, jaccard_index, boundary_f1_score])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths for data and masks\n",
    "train_data_path = r'/home/icmr/Documents/JIP_DATASET/PORTAL/Train/imageTr'\n",
    "train_mask_path = r'/home/icmr/Documents/JIP_DATASET/PORTAL/Train/LabelTr'\n",
    "\n",
    "val_data_path = r'/home/icmr/Documents/JIP_DATASET/PORTAL/Val/imageVal'\n",
    "val_mask_path = r'/home/icmr/Documents/JIP_DATASET/PORTAL/Val/LabelVal'\n",
    "\n",
    "test_data_path = r'/home/icmr/Documents/JIP_DATASET/PORTAL/Test/imageTs'\n",
    "test_mask_path = r'/home/icmr/Documents/JIP_DATASET/PORTAL/Test/LabelTs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/icmr/myenv_py311/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Verify paths exist\n",
    "for path in [train_data_path, train_mask_path, val_data_path, val_mask_path, test_data_path, test_mask_path]:\n",
    "    if not os.path.exists(path):\n",
    "        raise FileNotFoundError(f\"Path not found: {path}\")\n",
    "\n",
    "# File lists for each dataset\n",
    "train_files = [filename for filename in os.listdir(train_data_path) if filename.endswith('.nii.gz')]\n",
    "val_files = [filename for filename in os.listdir(val_data_path) if filename.endswith('.nii.gz')]\n",
    "test_files = [filename for filename in os.listdir(test_data_path) if filename.endswith('.nii.gz')]\n",
    "\n",
    "batch_size = 1\n",
    "\n",
    "# Data generators\n",
    "train_generator = data_generator(train_files, train_data_path, train_mask_path, batch_size, target_shape=input_shape[:3])\n",
    "val_generator = data_generator(val_files, val_data_path, val_mask_path, batch_size, target_shape=input_shape[:3])\n",
    "test_generator = data_generator(test_files, test_data_path, test_mask_path, batch_size, target_shape=input_shape[:3])\n",
    "\n",
    "\n",
    "# Calculate steps per epoch\n",
    "steps_per_epoch = len(train_files) // batch_size\n",
    "validation_steps = len(val_files) // batch_size\n",
    "test_steps = len(test_files) // batch_size\n",
    "\n",
    "# Save the model\n",
    "model.save('unet3d_new_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    }
   ],
   "source": [
    "# Define custom callback for metrics\n",
    "class MetricsLogger(Callback):\n",
    "    def __init__(self, val_generator, val_steps, test_generator, test_steps):\n",
    "        super().__init__()\n",
    "        self.val_generator = val_generator\n",
    "        self.val_steps = val_steps\n",
    "        self.test_generator = test_generator\n",
    "        self.test_steps = test_steps\n",
    "        self.logs = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        # Evaluate on validation set\n",
    "        val_loss, val_accuracy, val_dice, val_jaccard, val_boundary= self.model.evaluate(\n",
    "            self.val_generator, steps=self.val_steps, verbose=0\n",
    "        )\n",
    "        # Evaluate on test set\n",
    "        test_loss, test_accuracy, test_dice, test_jaccard, test_boundary = self.model.evaluate(\n",
    "            self.test_generator, steps=self.test_steps, verbose=0\n",
    "        )\n",
    "        # Log metrics\n",
    "        self.logs.append({\n",
    "            'epoch': epoch + 1,\n",
    "            'train_loss': logs.get('loss'),\n",
    "            'train_accuracy': logs.get('accuracy'),\n",
    "            'val_loss': val_loss,\n",
    "            'val_accuracy': val_accuracy,\n",
    "            'val_dice': val_dice,\n",
    "            'val_jaccard': val_jaccard,\n",
    "            'val_boundary' : val_boundary,\n",
    "            'test_loss': test_loss,\n",
    "            'test_accuracy': test_accuracy,\n",
    "            'test_dice': test_dice,\n",
    "            'test_jaccard': test_jaccard,\n",
    "            'test_boundary' : test_boundary\n",
    "        })\n",
    "        print(f\"Epoch {epoch + 1}: \"\n",
    "              f\"Train Loss: {logs.get('loss')}, Train Accuracy: {logs.get('accuracy')}, \"\n",
    "              f\"Val Loss: {val_loss}, Val Accuracy: {val_accuracy}, \"\n",
    "              f\"Test Loss: {test_loss}, Test Accuracy: {test_accuracy}\")\n",
    "\n",
    "# Define callbacks\n",
    "checkpoint = ModelCheckpoint('unet3d_new_model.h5', save_best_only=True, monitor='val_loss', mode='min')\n",
    "metrics_logger = MetricsLogger(val_generator, validation_steps, test_generator, test_steps)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=50,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    validation_steps=validation_steps,\n",
    "    callbacks=[checkpoint, metrics_logger, early_stopping]\n",
    ")\n",
    "\n",
    "# Final evaluation on test set\n",
    "final_test_loss, final_test_accuracy, final_test_dice, final_test_jaccard, final_boundary_f1_score = model.evaluate(\n",
    "    test_generator, steps=test_steps\n",
    ")\n",
    "print(\"\\nFinal Test Metrics:\")\n",
    "print(f\"Test Loss: {final_test_loss}\")\n",
    "print(f\"Test Accuracy: {final_test_accuracy}\")\n",
    "print(f\"Test Dice Coefficient: {final_test_dice}\")\n",
    "print(f\"Test Jaccard Index: {final_test_jaccard}\")\n",
    "print(f\"Test Boundary F1 Score: {final_boundary_f1_score}\")\n",
    "\n",
    "# Save metrics logs\n",
    "\n",
    "metrics_df = pd.DataFrame(metrics_logger.logs)\n",
    "metrics_df.to_csv('metrics_log.csv', index=False)\n",
    "\n",
    "# Display metrics as a table\n",
    "print(\"\\nMetrics per Epoch:\")\n",
    "print(metrics_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
